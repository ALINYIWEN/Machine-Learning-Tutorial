{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入所需套件\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation, Flatten\n",
    "from keras.optimizers import Nadam\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# 設定隨機種子\n",
    "np.random.seed(42)\n",
    "rn.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 設定介面與字型\n",
    "plt.style.use('ggplot')\n",
    "## 正常顯示中文為標楷體\n",
    "plt.rcParams['font.family'] = 'DFKai-SB'\n",
    "## 用來正常顯示負號\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train (2823, 224, 224, 3)\n",
      "shape of y_train (2823, 5)\n",
      "shape of x_test (2000, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 資料生成函數\n",
    "def make_data(directory_names, imagesize):\n",
    "    image_of_data = []\n",
    "    label_of_data = []\n",
    "    test_id = []\n",
    "    # 讀取資料夾下所有影像\n",
    "    for i, directory_name in enumerate(directory_names):\n",
    "        for filename in os.listdir(r'data/' + directory_name + '/'):\n",
    "            img = cv2.imread(r'data/' + directory_name + '/' + filename)\n",
    "            img = cv2.resize(img, (imagesize, imagesize))\n",
    "            image_of_data.append(np.array(img))\n",
    "            if directory_name == 'test':\n",
    "                test_id.append(filename[:-4])\n",
    "            else:\n",
    "                label_of_data.append(i)\n",
    "    image_of_data = np.array(image_of_data)\n",
    "    label_of_data = np.array(label_of_data)\n",
    "\n",
    "    return image_of_data, test_id if directory_name == 'test' else label_of_data\n",
    "        \n",
    "# 設定參數\n",
    "train_directory_names = ['image_data/train/daisy', 'image_data/train/dandelion', 'image_data/train/rose', 'image_data/train/sunflower', 'image_data/train/tulip']\n",
    "test_directory_names = ['image_data/test']\n",
    "imagesize = 224\n",
    "\n",
    "# 套用函數\n",
    "x_train, y_train = make_data(train_directory_names, imagesize)\n",
    "x_test, test_id = make_data(test_directory_names, imagesize)\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "y_train = to_categorical(y_train, 5)\n",
    "\n",
    "# 輸出資料型態\n",
    "print('shape of x_train', x_train.shape)\n",
    "print('shape of y_train', y_train.shape)\n",
    "print('shape of x_test', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train (2258, 224, 224, 3)\n",
      "shape of y_train (2258, 5)\n",
      "shape of x_val (565, 224, 224, 3)\n",
      "shape of y_val (565, 5)\n"
     ]
    }
   ],
   "source": [
    "# 從train資料中分出val資料\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "print('shape of x_train', x_train.shape)\n",
    "print('shape of y_train', y_train.shape)\n",
    "print('shape of x_val', x_val.shape)\n",
    "print('shape of y_val', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 10\n",
    "epochs = 100\n",
    "\n",
    "# callbacks\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=15, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.8, min_lr=1e-12, monitor='val_accuracy', patience=3, verbose=1)\n",
    "callbacks = [earlystop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             zoom_range=0.1, # Randomly zoom image \n",
    "                             width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "                             height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "                             horizontal_flip=True)  # randomly flip images\n",
    "        \n",
    "datagen.fit(x_train)ㄡ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 9s 0us/step\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 111, 111, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 109, 109, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 109, 109, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 109, 109, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 54, 54, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 54, 54, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 54, 54, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 52, 52, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 52, 52, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 52, 52, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 25, 25, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 25, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 25, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 12, 12, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 12, 12, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 12, 12, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 12, 12, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 12, 12, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 12, 12, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 12, 12, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 5, 5, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 5, 5, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 5, 5, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 5, 5, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 5, 5, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 5, 5, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5, 5, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            2565        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 22,854,437\n",
      "Trainable params: 22,820,005\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\ALIN\\AppData\\Local\\Temp/ipykernel_95228/3440548432.py:19: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/100\n",
      "225/225 [==============================] - 107s 474ms/step - loss: 1.1840 - accuracy: 0.5627 - val_loss: 202.1831 - val_accuracy: 0.2088\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 78s 345ms/step - loss: 0.9363 - accuracy: 0.6575 - val_loss: 1.6044 - val_accuracy: 0.3646\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 78s 346ms/step - loss: 0.8386 - accuracy: 0.7076 - val_loss: 1.6824 - val_accuracy: 0.5345\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 78s 346ms/step - loss: 0.8277 - accuracy: 0.7135 - val_loss: 1.0985 - val_accuracy: 0.5965\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 78s 346ms/step - loss: 0.7150 - accuracy: 0.7562 - val_loss: 0.9161 - val_accuracy: 0.6903\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 79s 350ms/step - loss: 0.6602 - accuracy: 0.7700 - val_loss: 1.3307 - val_accuracy: 0.6053\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 80s 357ms/step - loss: 0.6231 - accuracy: 0.7789 - val_loss: 1.0246 - val_accuracy: 0.6938\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 79s 353ms/step - loss: 0.6129 - accuracy: 0.7798 - val_loss: 0.8712 - val_accuracy: 0.7221\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 59s 262ms/step - loss: 0.5587 - accuracy: 0.8029 - val_loss: 1.0044 - val_accuracy: 0.6903\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.5397 - accuracy: 0.8109 - val_loss: 0.5626 - val_accuracy: 0.8018\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.5112 - accuracy: 0.8238 - val_loss: 0.5342 - val_accuracy: 0.8018\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.4791 - accuracy: 0.8310 - val_loss: 1.1578 - val_accuracy: 0.7204\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.4757 - accuracy: 0.8341 - val_loss: 0.5477 - val_accuracy: 0.8088\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 52s 231ms/step - loss: 0.4712 - accuracy: 0.8310 - val_loss: 0.4768 - val_accuracy: 0.8478\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.4594 - accuracy: 0.8354 - val_loss: 0.7450 - val_accuracy: 0.7717\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.4599 - accuracy: 0.8390 - val_loss: 0.4917 - val_accuracy: 0.8212\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4061 - accuracy: 0.8679\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.4061 - accuracy: 0.8679 - val_loss: 0.7980 - val_accuracy: 0.7575\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.3464 - accuracy: 0.8826 - val_loss: 0.5916 - val_accuracy: 0.8088\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.3476 - accuracy: 0.8741 - val_loss: 0.5527 - val_accuracy: 0.8106\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.3154 - accuracy: 0.8964 - val_loss: 0.4559 - val_accuracy: 0.8513\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.3532 - accuracy: 0.8763 - val_loss: 0.8270 - val_accuracy: 0.7522\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.3339 - accuracy: 0.8879 - val_loss: 0.9837 - val_accuracy: 0.7540\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3353 - accuracy: 0.8821\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.3353 - accuracy: 0.8821 - val_loss: 0.5323 - val_accuracy: 0.8248\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.2527 - accuracy: 0.9115 - val_loss: 0.5782 - val_accuracy: 0.8159\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.2422 - accuracy: 0.9106 - val_loss: 0.5099 - val_accuracy: 0.8389\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.9133\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.2525 - accuracy: 0.9133 - val_loss: 0.5001 - val_accuracy: 0.8389\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.2237 - accuracy: 0.9293 - val_loss: 0.5203 - val_accuracy: 0.8549\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.2025 - accuracy: 0.9262 - val_loss: 0.4969 - val_accuracy: 0.8531\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.1859 - accuracy: 0.9391 - val_loss: 0.4319 - val_accuracy: 0.8619\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.1734 - accuracy: 0.9399 - val_loss: 0.3880 - val_accuracy: 0.8938\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.1871 - accuracy: 0.9404 - val_loss: 0.4078 - val_accuracy: 0.8761\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.1997 - accuracy: 0.9284 - val_loss: 0.5409 - val_accuracy: 0.8496\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1508 - accuracy: 0.9475\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.1508 - accuracy: 0.9475 - val_loss: 0.3817 - val_accuracy: 0.8814\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.1498 - accuracy: 0.9502 - val_loss: 0.3926 - val_accuracy: 0.8796\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.1179 - accuracy: 0.9582 - val_loss: 0.4493 - val_accuracy: 0.8850\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.9506\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.1362 - accuracy: 0.9506 - val_loss: 0.5149 - val_accuracy: 0.8336\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.1275 - accuracy: 0.9586 - val_loss: 0.3653 - val_accuracy: 0.8832\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.1010 - accuracy: 0.9684 - val_loss: 0.4537 - val_accuracy: 0.8885\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.9706\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0919 - accuracy: 0.9706 - val_loss: 0.4405 - val_accuracy: 0.8814\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0673 - accuracy: 0.9773 - val_loss: 0.4910 - val_accuracy: 0.8655\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0896 - accuracy: 0.9680 - val_loss: 0.3489 - val_accuracy: 0.8956\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0706 - accuracy: 0.9755 - val_loss: 0.4275 - val_accuracy: 0.8832\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0783 - accuracy: 0.9702 - val_loss: 0.3763 - val_accuracy: 0.9009\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0646 - accuracy: 0.9773 - val_loss: 0.4979 - val_accuracy: 0.8743\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0643 - accuracy: 0.9782 - val_loss: 0.4003 - val_accuracy: 0.8920\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0685 - accuracy: 0.9760 - val_loss: 0.3422 - val_accuracy: 0.9186\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0569 - accuracy: 0.9831 - val_loss: 0.3918 - val_accuracy: 0.9097\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0479 - accuracy: 0.9831 - val_loss: 0.4548 - val_accuracy: 0.8903\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.9822\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0643 - accuracy: 0.9822 - val_loss: 0.3796 - val_accuracy: 0.8938\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 0.3862 - val_accuracy: 0.9080\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0523 - accuracy: 0.9800 - val_loss: 0.4556 - val_accuracy: 0.8920\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9813\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0474 - accuracy: 0.9813 - val_loss: 0.4032 - val_accuracy: 0.9115\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0409 - accuracy: 0.9858 - val_loss: 0.3607 - val_accuracy: 0.9204\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0498 - accuracy: 0.9827 - val_loss: 0.3765 - val_accuracy: 0.9062\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0280 - accuracy: 0.9898 - val_loss: 0.3813 - val_accuracy: 0.9027\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9911\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0324 - accuracy: 0.9911 - val_loss: 0.3533 - val_accuracy: 0.9044\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 52s 229ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.3596 - val_accuracy: 0.9080\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0329 - accuracy: 0.9898 - val_loss: 0.3784 - val_accuracy: 0.9062\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9858\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "225/225 [==============================] - 52s 232ms/step - loss: 0.0408 - accuracy: 0.9858 - val_loss: 0.3764 - val_accuracy: 0.8991\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 52s 231ms/step - loss: 0.0318 - accuracy: 0.9884 - val_loss: 0.3554 - val_accuracy: 0.9150\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 54s 239ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.3257 - val_accuracy: 0.9204\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 0.9898\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 0.3805 - val_accuracy: 0.9062\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 52s 230ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.3773 - val_accuracy: 0.9133\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 52s 231ms/step - loss: 0.0211 - accuracy: 0.9920 - val_loss: 0.3781 - val_accuracy: 0.9133\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 59s 264ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.3746 - val_accuracy: 0.9239\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 71s 314ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.3800 - val_accuracy: 0.9221\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 71s 314ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.3854 - val_accuracy: 0.9168\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9942\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "225/225 [==============================] - 71s 314ms/step - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.3456 - val_accuracy: 0.9239\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 71s 314ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 0.3755 - val_accuracy: 0.9186\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 71s 316ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.4082 - val_accuracy: 0.9133\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9942\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "225/225 [==============================] - 71s 317ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.4002 - val_accuracy: 0.9080\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 73s 325ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.3786 - val_accuracy: 0.9186\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 84s 373ms/step - loss: 0.0129 - accuracy: 0.9947 - val_loss: 0.3885 - val_accuracy: 0.9204\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9978\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "225/225 [==============================] - 75s 334ms/step - loss: 0.0089 - accuracy: 0.9978 - val_loss: 0.3877 - val_accuracy: 0.9221\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 78s 346ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.3896 - val_accuracy: 0.9221\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 78s 348ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.3789 - val_accuracy: 0.9257\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 79s 350ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.3873 - val_accuracy: 0.9274\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 80s 354ms/step - loss: 0.0224 - accuracy: 0.9956 - val_loss: 0.4027 - val_accuracy: 0.9292\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 79s 352ms/step - loss: 0.0096 - accuracy: 0.9973 - val_loss: 0.3930 - val_accuracy: 0.9204\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 78s 349ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.3810 - val_accuracy: 0.9274\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9964\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "225/225 [==============================] - 80s 354ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.3800 - val_accuracy: 0.9257\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 80s 355ms/step - loss: 0.0068 - accuracy: 0.9978 - val_loss: 0.3999 - val_accuracy: 0.9204\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 75s 332ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.4172 - val_accuracy: 0.9221\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9982\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "225/225 [==============================] - 75s 335ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.4051 - val_accuracy: 0.9204\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 79s 352ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 0.4032 - val_accuracy: 0.9239\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 79s 352ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.4064 - val_accuracy: 0.9221\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9973\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "225/225 [==============================] - 79s 351ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.4130 - val_accuracy: 0.9186\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 79s 351ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.4141 - val_accuracy: 0.9221\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 79s 352ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.4171 - val_accuracy: 0.9274\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "225/225 [==============================] - 80s 355ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 0.4120 - val_accuracy: 0.9257\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 79s 351ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.4196 - val_accuracy: 0.9204\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 80s 356ms/step - loss: 0.0095 - accuracy: 0.9982 - val_loss: 0.4297 - val_accuracy: 0.9150\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9987\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "225/225 [==============================] - 80s 355ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.4330 - val_accuracy: 0.9115\n",
      "Epoch 00093: early stopping\n",
      "val loss: 0.4329695999622345\n",
      "val accuracy: 0.9115044474601746\n"
     ]
    }
   ],
   "source": [
    "# Build training model\n",
    "inceptionv3 = InceptionV3(include_top=False, input_shape=(imagesize, imagesize, 3)) \n",
    "x = inceptionv3.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# 添加一個全連接層\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "# 添加一個分類器\n",
    "output = Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs=inceptionv3.input, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Nadam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size, \n",
    "                              validation_data=(x_val,y_val),\n",
    "                              verbose=1, \n",
    "                              callbacks=callbacks)\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('val loss:', score[0])\n",
    "print('val accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsSklEQVR4nO3dfXQc1WH+8e/MrKSVZRtJrN5s41ewa2MMtY2BUJsorE0ghZw2FBOXxD62S4D84ZO2SSktpCShVUKJKbgNOT9ISSG45tBwSnIINOuAhWp6GmNLgDEVssEoYFnWm/Wy2reZ+f2xq5VkyVgS3pWseT7n+NgzO7Nz90qeZ++dO3MN13VdRETEk8zxLoCIiIwfhYCIiIcpBEREPEwhICLiYQoBEREPUwiIiHiYQkDOWd3d3XR2dqaXHceho6Nj0LqRcl2XcDg8qn2i0SgjHWHdV7axlk8kUxQCcs7atWsX559/PpFIBIBQKERRURH/9E//NKr3+dnPfsaFF17ICy+8MKLte3p6uP322ykvL6enp2dE+3R1dfGtb32LQCDA888/P6ryiWSSQkDOWV/84hdJJBLU1dUBcOjQIQC+8pWvjOp9/vRP/5Rly5aNePuCggIeffRRuru7R7zPeeedx+23305hYSEbN24cVflEMkkhIOe0iooK9u/fD5BuEYyFZVmj2j4vL2/U+4hMRL7xLoDIp7FixQreeOMNINnvfqqdO3dy+PBhOjo6uPnmm7nyyivTrz377LPs3buXCy+8ENu2B+138uRJHnvsMXp6eigsLOSuu+7C7/dn9LM0Njby1FNP0dPTQ1FREV//+tfJz88Hkt1JO3bsIC8vj/z8fLq7u/nmN78JJK9nPPHEE7S0tDBt2jRisRhf+tKXmD17dkbLK5ODWgJyTusLgXg8js83+DvNtm3biEaj/O3f/i1///d/z49+9CNCoRAAjz32GAcPHmT79u3ceOON6SABsG2bG264gVWrVvGd73yHNWvWcNttt2X0cxw5coSNGzdy55138sADD3D11Vezfv369IXnO+64g3nz5vHnf/7nbNy4kUOHDvHaa68B8Pjjj7Nv3z7uvvtu7rrrLvLz83nqqacyWl6ZPBQCck5btGgRjY2N1NbWctFFF6XXHz58mN/85jds2rQJgNzcXB544AG+9a1vAfDAAw/wzW9+E8MwmDNnDqtWrUrv+9xzz7FkyRIqKysBWLlyJW1tbbzzzjsZ+xz3338/d9xxB0VFRQBcddVVlJaW8otf/AKAd955h/b2dgCmTJnCj3/843TL5J133qG7u5t4PI5hGNxxxx3psouciUJAzmmGYbB06VKefvppli5dml6/f/9+Lr300kHbzpo1i4aGBo4ePYphGEydOnXY93z55Zfp7u7mH//xH9N/Vq1aNaoLwaO1b98+li9fPmjdokWLeP311wH4/ve/zw9/+EMuvvhiqqqqaG9v5/LLLweSLZ7GxkYuuOACvvGNb/D222/zmc98JmNllclF1wTknLdy5UqeffZZtm/fnl7nui6GYQzZ1ufznbFvPxqN8oUvfCHjXUCQLOdHH300bHnz8vLS9y6sW7eO+vp69u7dy1NPPcUll1zCCy+8wBVXXMHcuXPZs2cPDQ0NPP3006xdu5b77ruPO++8M+Pll3OfWgJyzlu5ciWlpaWYZv+v8yWXXJIeOtrn+PHjFBYWUlZWRjQaTXevnGrFihXs2bNn0Lr29nY+/vjjs172F198kcbGRi655BJqa2sHvfbuu++yYsUKDh06xCOPPIJhGFx99dU89thjbNy4keeffx7Hcfj6178OwIUXXsjf/d3f8cQTT/DTn/70rJdVJieFgJyzEokEtm2zcuVKLr744vQIH8dxWLx4MZdeeilPP/00ALFYjL/+67/mH/7hHwC4++67+c53voPjODQ2NrJv3750KGzdupWamhp+9KMf0djYyKuvvsqDDz5IeXl5+titra3E43FOnDgx4vJ2d3cTiUSIx+NAsgvojjvuYNGiRdx33308/PDDnDx5Mv3aoUOHWL9+PYsXL+bxxx/nxz/+MbZtE4vFOHToEFdddRWmaWLbNnfddVf6TuS6ujquuuqqT1m74hWGZhaTc9Xjjz/O0aNH+fa3v827777L+++/z+7du5k1axZ/+Zd/ieM4/PSnP+XYsWPE43Guv/76QReAn3zySQ4cOMCsWbMoKCjg6NGjfPnLX+ayyy6jtbWVHTt20NDQwMqVK7nrrrvIyckBoKOjgx/84AeEw2Hy8/PZuHEjv/d7v/eJZW1ra+PBBx+kt7eX6dOnk0gkCIfD+P1+qqqqAHjvvffYtWsXANOnT+f2229Pd1398pe/pLW1lQMHDuA4DsFgkJtuuglInvRra2t55513CIfDLFq0iNtvv53c3NyzXucy+SgEREQ8TN1BIiIephAQEfEwhYCIiIcpBEREPOycvFlsrOO1A4EALS0tZ7k05x7VQ5LqoZ/qImky18OMGTOGXa+WgIiIhykEREQ8TCEgIuJh5+Q1ARGRkXJdl0gkguM4wz5UcKDjx48TjUazVLKzz3VdTNPE7/ef8bP2UQiIyKQWiUTIyckZMunQcHw+3zk/bWgikSASiaRnpTsTdQeJyKTmOM6IAmCy8Pl8w061ejoZD4FEIjFoORaLDdlmuHVn28lIgqbOsU9ELiLnppF2i0wmo/nMGYvHSCRCTU0NeXl5HDp0iI0bN/Lzn/+ckpISmpub2bBhA5CcCPzUdZnwk/3N1Lc28qMb52XsGCIiZ1sikchoSyZjLYHa2lpmz57N6tWrKS8v54033iAcDhMMBmlpaSEcDtPV1TVkXaZYhkHC0QNTRWR8jOUm10QikZ4nO1MyFi9z587l4MGDLFy4kCNHjrBkyRKampoAKC4upqmpCdd10xNr962bP39+RsrjMw1shYCIpzn//v9wG98//euGwWifrm9cMA/z1j8743YvvPACd9xxx6je2+fzpSdGypSMhUB5eTnl5eU0NDQwffp0Ojo60k0ay7Lo7e2lt7d3yLrhhEIhQqEQAFVVVQQCgVGXp2DKSWy3Z0z7TjY+n0/1gOphoMlcF8ePH0+fZxKmiXOG/vLRXkMwTfMTu2s++ugjdu3axd69e1m4cCHTpk2jtraWa6+9lp/85CesWLGCm266if/8z/9k6tSpmKbJ5z//eQD27NnD4cOH2bx5c3q5ubmZWCxGV1fXaUMlLy9vxD/PjF4y7+rqYu/evWzatIm6urr0FWvXdbEsC8uyhqwbTjAYJBgMppfH8myPWDRCwnYm7XNBRmMyPx9lNFQP/SZzXUSj0f5zyy1bPrEP3OfzDRnMMhKftE9ZWRm33XYbR44c4XOf+xy9vb3cf//9BAIB7r33Xtrb23n22Wfp7Ozkj//4j7nzzjtZvXo1eXl5rFq1in/+53/mq1/9KgDhcJj/+Z//4fvf/z733Xcfb7/99rCz2kWj0SE/z3F5dtDu3bu59dZbMU2TvLy8dJ9/T0/yG3lpaemQdZniMw1sTaImIuMsPz+fwsJCbrzxRvLy8igvL+fWW2/loosuYteuXRw7doxIJDmS8dT7GwoKCpg3Lzm4pbi4mJ6enk9dnoyFQFNTE52dndTW1hIKhYjFYrS1tRGLxYhGowQCAWbOnDlkXaaYBromICITwqldSA8//DA+n4/169dzwQUXZLcsmXpjwzCYOXMmXV1dGIbB/PnzWb9+PXv27Bk0FHS4dZmg0UEiMl7y8vLo7OykpaWFhoYG4vH4oNcbGhqYMWMGv/vd7/joo484ePAgAPF4nM7OzvR2iUQifV9VIpEY8j5jkbFrAmVlZZSVlQ1Zv3bt2kHLJSUlQ9Zlgs80cFxwXBfTgzePiMj4KSgo4Oabb+aNN96goqKCm266iVdeeYXKykoA7r//fn75y1+ydOlSvvvd76Yf+fDaa69xyy238Nvf/pbLL7+cRCKRPq/Onj37rAyrN9zRjoeaAMYy3vbZt1v4WV0L//HlRfhMb4fAZL4IOBqqh36TuS7C4TBTpkwZ0bZjvTA80Qz3mT0/qYyV+vav6wIiIv08EwJ93/41QkhEpJ9nQqCvB8ge+cP1REQmPc+EgGWqO0hE5FTeCQFD3UEiMrGNZh6As8U7IZD6pOoOEpGJ6JVXXmH9+vVZP65npttRS0BEHt93nPfbTz+5lDGGp4jOK/KzdeXQe6JGq7Kykp/85Cef+n1GyzshoGsCIjIOfvazn9Hc3Mw3vvENnnvuOXJycojFYkydOhXLsli3bl162/GYBc1DIZD821YGiHjWmb6xZ+JmsSuuuIJ/+Zd/AaCwsJBjx44RDof5kz/5E+68806uueYa8vLyzuoxR8M71wR0s5iIjIMLL7yQ48ePE4vFcByH2267bdgnho4X74WArgmISJYFg0F+9atfMXXq1HF9YuhwvBMCGh0kIuPki1/8Io8++iiXX375aZ8Yats27e3tWS+bh0JALQERGR/FxcU89NBD5OTkcP/991NTU0NTUxPf/e53KS8vB+B///d/+fKXv8zrr7+e1bJ558KwrgmIyDi69NJLgeQTWzdt2jTk9auuuoqrrroqy6XKQkvgbEx6cDZodJCIyFAZbQlUV1dTU1PDPffcw8GDB3nmmWeYNm0atm2zaNEiPve5z7F9+3YKCgrIz89n27ZtGSuLWgIi3nQOTpnyqY3mM2c0BNasWcPLL78MJC963Hvvvfj9fvbu3cvSpUuJRCJs3rw5PXFyJulmMRFvMk2TRCIxaE7fySyRSGCaI+/kyVqtLFu2DEg+IKmzs5Pp06fT09NDb28vNTU1LFiwgIqKimH3DYVChEIhAKqqqsY0If1JeoAPmDJ1WkYntD8X+Hw+z9cBqB4Gmsx14boubW1tI7oJzHGcc77lkJOTQ1lZ2YjvPs56NO7fv58FCxakl48ePUplZSU7duxg69atFBYWDtknGAwSDAbTy2OZBq/zZBSAjpOdTNJZ9EZsMk8lOBqqh35eqAvLss64zWSoB9d1aW1tHbJ+wkwvWVdXx5w5cwCoqKjg+uuvx+/3s2TJEt56662MHVc3i4mIDJX1EDh+/Di5ubkANDU1UVdXB0AkEiE/Pz9jx+2/WUwhICLSJ6MhYNs2tm0PWheNRtP/bm9vp7W1lVgsRn19PUuXLs1YWfpvFsvYIUREzjkZDYG6ujrWrVvH4cOH0+tuueWW9L8XL15MIBCgurqaLVu24Pf7M1YWDREVERkqoxeGly9fPmTdxRdfPGi5b9RQpll9E83rmoCISJr3nh2kB8iJiKR5MATUEhAR6eOdEFB3kIjIEN4JAY0OEhEZwjMhYBoGBuoOEhEZyDMhAMnWgEJARKSfp0LAZxrqDhIRGcBTIaCWgIjIYN4LAY0OEhFJ81QI+ExDN4uJiAzgqRBQS0BEZDBvhYChawIiIgN5KgQ0OkhEZDBPhYBGB4mIDJbxEIjH42fcJhaLZboYgK4JiIicKqPzCVRXV1NTU8M999xDW1sb27dvp6CggPz8fLZt2wbAzp07KSkpobm5mQ0bNmSyOBodJCJyioyGwJo1a3j55ZcBSCQSbN68mXnz5qVf7+rqIhwOEwwGeeSRRwiHw0yZMiVj5bFMA0ctARGRtKxdE7Btm97eXmpqajh27BgAzc3NFBUVAVBcXExTU1NGy2CZBgldExARSctoS+BUR48epbKykh07drB161ba29vx+ZJFsCyL3t7eYfcLhUKEQiEAqqqqCAQCYzp+jnUMMMe8/2Th8/k8XwegehhIdZHkxXrIWghUVFRQUVEBwJIlS3jrrbeYOnUqjpPspHddF8uyht03GAwSDAbTyy0tLWMqgwn0RmNj3n+yCAQCnq8DUD0MpLpImsz1MGPGjGHXZ607qKmpibq6OgAikQj5+fmUlpYSDocB6OnpyXgCqztIRGSwjIaAbdvYtg1Ae3s7ra2txGIx6uvrWbp0KTNnzqStrY1YLEY0Gs1KCOhmMRGRfhntDqqrq2PdunUcPnyYxYsXE4/Hqa6uZsuWLfj9fgDWr1/Pnj17Mj48FJJDRDU6SESkX0ZDYPny5YOWly1bNmSbkpIS1q5dm8lipKk7SERkMA8+NmK8SyEiMnF4KgTUHSQiMpinQsAy1B0kIjKQt0JAo4NERAbxVAj4TANHLQERkTRPhYBlGiR0TUBEJM1zIaDRQSIi/TwVAhodJCIymKdCQDeLiYgM5q0QMAwcN/nEUhER8VgI+CwDADUGRESSPBUClpEMAU02LyKS5K0QMJMhoOsCIiJJngoBXyoEHA0TFREBPBYCfS0BdQeJiCRlPATi8fig5UQikelDnpa6g0REBsvopDLV1dXU1NRwzz33EIlEqKmpIS8vj0OHDrFx40Z6enrYvn07BQUF5Ofns23btkwWp787SBkgIgJkOATWrFnDyy+/DEBtbS2zZ89m4cKFtLe3s3//fhYsWMDmzZuZN29eJouRlu4OUgqIiAAZDoGB5s6dy8GDB1m4cCFHjhxh6dKl2LZNb28vNTU1LFiwgIqKimH3DYVChEIhAKqqqsY8IX1ueysA0woLCRRNGdsHmQR8Pt+Y63AyUT30U10kebEeshYC5eXllJeX09DQwPTp05k/fz7Hjh3j6NGjVFZWsmPHDrZu3UphYeGQfYPBIMFgML3c0tIytkKkLgi3trZTYIfH9h6TQCAQGHsdTiKqh36qi6TJXA8zZswYdn1WRwd1dXWxd+9eNm3aBEBFRQXXX389fr+fJUuW8NZbb2X0+D6NDhIRGSSrIbB7925uvfVWTNPkxIkTNDU1UVdXB0AkEiE/Pz+jx9foIBGRwTLaHWTbNrZtA9DU1ERnZye1tbV0dnYSCATIy8ujtbWVWCxGfX09N9xwQyaLkw4BZYCISFJGQ6Curo5169Zx+PBhpk6dysyZM+nq6sIwDObPn8/06dOJx+NUV1ezZcsW/H5/JouDz0w2fDQ6SEQkKaMhsHz58kHLZWVlQ7ZZtmxZJoswiJXq/FJ3kIhIkrceG2GoO0hEZCBPhYDPUneQiMhAngqBvpZAQkNERUQAr4VA6tPqUdIiIkmeCoH06CC1BEREAI+FgG4WExEZzJMhoAwQEUkaVQjU19fT3d1NLBbjv/7rvzhw4ECmypURPj1KWkRkkBHfLLZnzx66u7tZuHAh//Zv/0Y0GuXjjz/Gdd0hN4VNVJpeUkRksBG3BCzL4gtf+AKxWIwDBw7wZ3/2Z2zatImjR49msnxnVd8QUVujg0REgFGEQDgcJpFI8Prrr7NixQoAWltbmTZtWsYKd7b5LLUEREQGGnEILFu2jG9/+9s8++yzXHfddXR0dPDII49QVFSUyfKdVf0tAYWAiAiM4ppAeXk53/ve9wAwDIMjR47wF3/xF0yfPj1jhTvb+ucYHueCiIhMEKMaHfTee+/R09NDLBajoaGBw4cPZ6pcGaGZxUREBsv46KB4PE5OTk56ORaLkZubO2ib4dZlQioDFAIiIikZHR1UXV3Ngw8+mF7euXMn1dXVPPPMM5+4LlMMw8Ay1B0kItIno6OD1qxZQ09PD5CcZD4cDhMMBmlpaSEcDg+7LtMs09CFYRGRlKyNDmpubk5vW1xcTFNT07DrMs0yDHUHiYikZG10UHt7Oz5f8nCWZdHb20tvb++QdcMJhUKEQiEAqqqqCAQCIy32ID6fD59lkpPnH/N7TAY+n8/Tn7+P6qGf6iLJi/UwqjmG29raeOmll2hqaqKkpITPf/7zIw4By7JwUg/yd10Xy7KGXTecYDBIMBhML7e0tIym2GmBQAATl55w75jfYzIIBAKe/vx9VA/9VBdJk7keZsyYMez6EXcHtbS08Nxzz7F8+XI2bNjA5Zdfzq5du2hubh7R/qWlpek+/56eHgKBwLDrMk3XBERE+o24JbB//362bNmS7r6pqKhg4cKF7N69m3Xr1g27j23b2LYNwMyZM2lrayMWixGNRtMn/OHWZZJlaIioiEifEbcEbNvGSD12oY9hGOmT/HDq6upYt25d+qay9evXs2fPHjZs2JDeZrh1mZRsCWTlUCIiE96IWwIrV67k0UcfZe3atZx//vm0tbXx4osvctttt512n1NvIispKWHt2rVnXJdJlqnRQSIifUYcAiUlJWzYsIGXXnqJ5uZmGhsbueaaa4jH45ks31mXvFlMISAiAqMcHVRaWspXv/rV9PKvf/1r9u/fzwUXXHDWC5YpyZbAeJdCRGRi+FRzDF977bWnHdY5UVmGRgeJiPT5xBDYt28fkUgEx3GG/ROLxQY9HO5cYJnqDhIR6fOJ3UGdnZ187WtfG/ZE77outm3zR3/0RxkrXCYkHxsx3qUQEZkYPjEEAoEATzzxRPregFO5rsuBAwcyUrBM0c1iIiL9PjEEli1b9ok7G4bxiXMJTESWATENERURAT7lheFzkW4WExHp580QUEtARATwYggY4KglICICeDAETMMgoZaAiAjgwRDwaXSQiEia50LAMsFRS0BEBPBgCJiGQULXBEREAA+GgCaaFxHp57kQ8Jng6JqAiAgwykdJnw0HDx7kmWeeYdq0adi2zcKFC3nzzTcpKCggPz+fbdu2ZfT4pqnuIBGRPlkPAdu2uffee/H7/ezdu5eysjJWrlzJvHnzsnJ8dQeJiPTLegj0PY/IcRw6OzuZN28e7e3t1NTUsGDBAioqKobsEwqFCIVCAFRVVY15Qnqfz8e0gik4bntWJrWfqHw+n6c/fx/VQz/VRZIX6yHrIdBn//79LFiwAICjR49SWVnJjh072Lp1K4WFhYO2DQaDBIPB9HJLS8uYjhkIBIhGekk4LidOnMAwjDGX/1wWCATGXIeTieqhn+oiaTLXw4wZM4ZdP24Xhuvq6pgzZw4VFRVcf/31+P1+lixZwltvvZXR41pm8sSva8MiIuMYAsePHyc3N5empibq6uoAiEQi5OfnZ/S4PqMvBJQCIiLjFgLRaBSA9vZ2WltbicVi1NfXs3Tp0owe10x9Yo0QEhEZx2sCt9xyCwCLFy8mHo9TXV3Nli1b8Pv9GT2ulWoJaISQiMg4hsDFF1+c/veZZjA7m3x91wR0UUBExHt3DKcygIQyQETEeyHQNzpIj5MWEfFgCKS7g3RNQETEeyGQ7g7S6CAREe+FgEYHiYj081wIaHSQiEg/z4VA381itjJARMR7IdDXHZRQS0BExHshoO4gEZF+nguBvtFB6g4SEfFgCPTdLKbuIBERL4aAHiUtIpLmvRDoGx2km8VERDwYAn2jg9QSEBGZOCEQi8WychxLo4NERNKyPp9AW1sb27dvp6CggPz8fLZt28bOnTspKSmhubmZDRs2ZPT4lm4WExFJy3oIJBIJNm/ezLx58wDo6uoiHA4TDAZ55JFHCIfDTJkyJWPH181iIiL9sh4Ctm3T29tLTU0NCxYsIBwOU1RUBEBxcTFNTU3Mnz9/0D6hUIhQKARAVVUVgUBgTMf2+XyUnF8MHGFKQcGY3+dc5/P5PPvZB1I99FNdJHmxHsZlesmjR49SWVnJjh07WLlyJT5fshiWZdHb2ztk+2AwSDAYTC+3tLSM6biBQICTHe0AnOzsHvP7nOsCgYBnP/tAqod+qoukyVwPM2bMGHZ91kOgoqKCiooKAJYsWYJlWThOcrym67pYlpXR4+tmMRGRflkfHdTU1ERdXR0AkUiE7u5uwuEwAD09PRlviulmMRGRflkPgfb2dlpbW4nFYtTX11NZWUlbWxuxWIxoNJr5EEiPDlIIiIhkvTto8eLFxONxqqur2bJlC36/n/Xr17Nnz56MDw+FgaODMn4oEZEJb1wuDC9btmzQcklJCWvXrs3KsXWzmIhIvwlzx3C2WOlHSSsEREQ8FwKGYWAa6g4SEQEPhgAkrwtodJCIiFdDwDSwdU1ARMSrIQAJZYCIiEdDwDA0OkhEBK+GgGlodJCICF4NAUPTS4qIgFdDQBeGRUQAr4aAoZvFRETAqyFgGppeUkQEr4aAoe4gERHwagiYKARERPBqCBjqDhIRgXEKgUQiMR6HTdPoIBGRpKzOJxCJRKipqSEvL49Dhw5x8803s337dgoKCsjPz2fbtm1ZKYdGB4mIJGU1BGpra5k9ezYLFy6kvb2dmpoaNm/ezLx587JZDCzTIKqHB4mIZLc7aO7cuTQ2NgJw5MgRFi9eTG9vLzU1NRw7dixr5UheE1AIiIhktSVQXl5OeXk5DQ0NTJ8+nalTp1JbW0tlZSU7duxg69atFBYWDtkvFAoRCoUAqKqqGvNk9D6fj0AgQL7/ON2JWMYntZ+o+urB61QP/VQXSV6sB8N1s/uVuKuri+eff57bbrsN0+xviLz44otMmzaN1atXn/E9Pv744zEdOxAI0NLSwj9U/45jXXEe+UJ2u6Emir568DrVQz/VRdJkrocZM2YMuz7ro4N2797NrbfeimmavPPOO9TV1QHJi8b5+flZKYNuFhMRScpqd1BTUxOdnZ3U1tbS2dlJR0cHxcXFxGIx6uvrueGGG7JSDl0TEBFJympLwDAMZs6cSVdXF4ZhsG7dOgKBANXV1WzZsgW/35+VciTvGM7KoUREJrSstgTKysooKysbtG7ZsmXZLAKgm8VERPp4+LERCgEREW+GgImeHSQigldDQKODREQAr4aArgmIiAAeDQHTUHeQiAh4NAR8poGjC8MiIt4MAcswcFwUBCLieZ4Mgb5HFumGMRHxOk+GgM8wALUEREQ8GQKWmQyBhEYIiYjHeTIEUhmgEUIi4nmeDAFfKgUctQRExOM8GQLp7iBdExARj/NkCKS7g9QSEBGP82QIpLuDlAEi4nETKgRisVhWjmOmhoh2x2w6ozbtvQm1CkTEk7I6qcwn2blzJyUlJTQ3N7Nhw4az/v7Oa/9F5/GPcKwccnzlwCz+8qWj6ddzDJdZfpfZfofSPIOCXIv8XAvT56MlBieiLq0RlzyfQWGeRaHfYmquRb7PJM9n4LNMYq5B1IG4a1A8xUf51FzKCnIoyDUxUsETjtscbY/yfkeUpq4YZVNzmVuYx5zCPKbmWYPKHE04dEZteuMOU3JNpuVa5PlMEo7LyUiCkxGbuONSkGtSkGORn2NiGcmQMw3SxwRwXZeumENrOM7hnnaOt3YSSbhEE05/Wafm4PeZuK6bbiWd+j4iMrlMiBDo6uoiHA4TDAZ55JFHCIfDTJky5ewe5OMPifxvNW5XJ8sMi80Vq7ANC59rY7oOzf5iPiwo462p5bTnTsc1AGzAxnAdimKdnB89SYeZy7u50+jKmYJrjLwhZbgOBi6O0X+i9zkJEmb/j8BybHyujeU62IZJ1Mod8j65TpyYmTOiY/pcm5zUn4iRQ8w884/bdB2cUz6Xz3WwcEhGQV+LycAF3NRaI/UvExcTFx8OlutipZbN1Ot9+zgYxAyTKBYxLHw45JPAj4MPJ72dC9iYOIZBAgOb1N+uiYWDHwe/YePDIYFJHJMEBmCky+Sk9uv7BH5s8gwbvwFxFxKp9+wrv5UqZ8w1iabez4dLjuGSi4OFm/4D4AA2BjZm6jfGxEm/l4sPt7/JbSTLk3CN1D5GejsLF9Poq8Nknbrpeh4sWdb+encH/Ez6fkrDtW3N9N8uRupYBoBpEbdd7EH79f9shxr82zDcq6bR/7md1LaOa+BA+mcxuGxu6ifX/yYjHbtx6vcU12VAXfS/mPwsRnrtoN0MMAwT23HT9ecOs/+ZvhINV+Qz7zV439N97G9dUcLC+RUjeq+RmhAh0NzcTFFREQDFxcU0NTUxf/789OuhUIhQKARAVVUVgUBg9Af5+t34tv0t8VgMt7eHTd1duLEYbjyKG4+nfmtS/6kTcSKRGN29MeKxGOebCXJccO2C5IUEpwfb7iRsQ9g1idgQd138ToJcN4HPSdCa8HHMzqEp4aPXNXFcFwfwuzbzzDDz6CHgRmgjh/edKXzgTKEbK3lCcg0sXM4z4kwnQb6boAcfXfjoMn343QSFRClyIlhOnLBj0e2Y9GKmTkDJE14cg7hrEMckD5uAGyFAhGI3ht+Nke8k8LkJWs18mswCjpsFRF0Tw7Gx7ASu62CnToI2ZvI/ZfJ/Crguppt67obj4BoGrtt3QjSxDYNEqiy2YeCkT4z9QZGXqq9c1yZumPTiI2LmYA/4D2O6LpZrY7k2ppMMI5/rpILSImL6iJq5xA2THCeBz7XxOYnU3sn/8qbrYKb2d4GolUfUyiVu+rBcG59jY7kJIFlOO/VckTw7Tq4TT4W1RdzwETd9JEwL2zCxU4FuOckvEpbrpL9UWI6NbVrYhkXCtPpP1W6yVL70cZOhaxsGtpF8XydVX65hYLjugBPPwFND8mfsGv2v9p2sDdzUfoOlgzW1j5P62zUMzNTP03LtU076w5+83EGvpI6b2s1N/Z44holjmOnPYKa+CCWP5Q46TrIcpMuVPlG7pwshhuw73D5GarmvXH3bD95vwKd1+0707in/dgfV9anHP7WMw5XZOE2i9f2cT903faQBr5UZnx3b+e8TTIgQaG9vx+dLFsWyLHp7ewe9HgwGCQaD6eWWlpYxHScQCNDa1pZcsHIhPxfyp552e3/qTyz151QWMC3151QzU38+STy177LUn2wJBAKD6rAIuDCLx58oTq2HbHFdd0RdbKdu5/Z9UXHdoefm9FdIt/9rcfrESP+69Akl9VXZTUZDIFCSrItB27mnnu0HHGvAC6cry/Cf6pTlU97DPd12fatHce2uL0z6m0rJf6TraOBryfWB8wO0tLZ8YhGGP9Yoth1QlOEPdJp6BfD5xvw7O2PGjGHXT4gQsCwLx0l+q3RdF8uyzrCHyLlrpNdYTt3OMIyh/R6jP/jwq30+DN+EOB2MKyMvDyM3b7yLkVUTYnRQaWkp4XAYgJ6enrPe3BERkeFNiBCYOXMmbW1txGIxotGoQkBEJEsmRAgArF+/nj179mRkeKiIiAxvwnQClpSUsHbt2vEuhoiIp0yYloCIiGSfQkBExMMUAiIiHma4rh6qLyLiVZ5qCdx9993jXYQJQfWQpHrop7pI8mI9eCoERERkMIWAiIiHeSoEBj6EzstUD0mqh36qiyQv1oMuDIuIeJinWgIiIjKYp0IgW3MYT1SJRGLQspfrY+Bn92o9nPq5vVoP0Wh00LLX6mHCPDso0zI9h/FEFolEqKmpIS8vj0OHDrFx40Z+/vOfe7Y+mpub+Y//+A/uvPNOz/5e7Ny5k4qKClpbW/nSl77kyXpIJBI8/vjjLF68mEOHDnH77beza9cuz9WDJ1oCA+cwbmlpSc9d4BW1tbXMnj2b1atXU15ezhtvvOHp+njxxReJx+Oe/b3o6Ojg5MmTfPazn6W1tZWOjg5P1sP//d//UVhYyDXXXIPf76e+vt6T9eCJEBhuDmMvmTt3Lo2NjQAcOXKE0tJSz9bHBx98QHl5OeDd34vf/e53FBYW0tTUxKZNm2htbfVkPcycOZODBw/S2dlJU1MTjuN4sh48EQJnmsN4sisvL+faa6+loaGB6dOn09HR4dn6qK2t5bLLLgO8+3sRDoc5duwYbW1tPPzwwzQ2NnqyHgoLC/n93/99/uZv/oY1a9YQDoc9WQ+eCAHNYZzsEtu7dy+bNm3ybH0cPHiQpUuXppe9Wg+maTJ37lyWLFnCRRddhM/n82Q91NfXY9s2P/jBD/j1r39NS0uLJ+vBEyGgOYxh9+7d3HrrrZimSV5enifro6enh7a2Nt58803a2tooLi72ZD1Mnz6drq4uIBmEzc3NnqyH+vp6Zs+eTX5+Ptdccw2maXqyHjwRAl6fw7ipqYnOzk5qa2sJhULEYjFP1seqVatYtWoVS5cupaioiDlz5niyHubPn8/7779PPB6nvr6eYDDoyXpYsmQJ7777Lq7r8t5777Fo0SJP1oNn7hg+ceIEtbW1rFixguLi4vEuTlYdP36ct99+O718+eWXE41GPVsfe/fuJRaLcdFFF5Gbm+vJejhx4gQHDhxg4cKFzJ0717P/P44ePcp7773HggULmDdvnifrwTMhICIiQ3miO0hERIanEBAR8TCFgIiIh3nm2UEin+Ttt9/m+PHjGIZB32WyK664gqlTp37q9/7www+JRCIsXLjwU7+XyNmmloAIsGjRIp588kmuvPJKLr30Uvbu3ctHH310Vt67vr6eV1999ay8l8jZphAQAXJycrAsiylTphAIBNiyZctZe2zArFmzzsr7iGSCuoNETtH3fCHTNKmurmbWrFm8+eabLFmyJN2l09zczL59+zBNk5UrV6ZvLOrt7eW1117DdV2KiopYtWpV+n3ffvttGhoaWLBgAZdccgkAx44d480336SgoIBEIsFnP/vZrH9e8Ta1BERSXNflv//7v3nllVeA5IPW/vVf/5VwOMyNN97ISy+9xAcffEBzczNPP/0069atIxgM8txzz9HS0kIkEuGhhx5i+fLlXHfddfziF7/g8OHDABw+fJjzzjuPm266iX//93+nq6sLx3F49NFHqays5Oqrr6a7u5t33313PKtAPEgtAZEUwzC48sorOX78OJB8vMJ5552XfuhcMBjkN7/5DZZlsW7duvQTJ9esWcNLL71EaWkpK1asSLcKvva1r1FWVsbhw4dZsGABF1xwAQDnnXcenZ2dFBQU0N7ezt69e/nMZz7DH/7hH9LZ2TkOn1y8TC0BkQEsy2LZsmXDvlZUVERraysnTpwY9EiBvmfzNzc3U1paml4/a9YscnJyTnss0zS5//77aWxs5K/+6q948sknycvLO3sfRmQEFAIip7jwwgtxXZeXXnpp0PrOzk6Kioo4//zzaWtrS6/v6OigpKSEkpISPvzww0H7DNzuVA0NDeTm5vKVr3yFhx56iFgsplFEknUKARGS883G43EikQjxeJydO3eSm5tLJBLhvffew3EcQqEQlZWVrF27ll/96lckEgkSiQShUIjrrruO1atXU1NTw5tvvklrayuvvPIKnZ2d2Ladfk49kF4uLS3lhz/8IS0tLZimSU5ODiUlJeNYC+JFeoCcCPDGG2/Q2NhIbm4uiUQCx3H4gz/4A773ve+xadMmPvjgg0Gjgz7++GNqa2uxLIvLLruMsrIyAE6ePMmePXuIRCJcccUVzJkzh1dffZWTJ0+yevVqent7+e1vf8uMGTNYtWoV+/bto729na6uLubMmcOKFSvGsxrEgxQCIqfx4Ycfct9993HPPffobl+ZtBQCIqdx7Ngxurq68Pv9zJ49e7yLI5IRCgEREQ/ThWEREQ9TCIiIeJhCQETEwxQCIiIephAQEfGw/w8gFnXdmsg7uAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABQAUlEQVR4nO3deXxU5b348c+ZNfs62UOAsAkCQUBAFBENrpeuKhbbql3scrtcf7W1ra3WVlta6621rV2urba3FbfWe70WtUYUBFxAZF8DhIQkk8kyyUxmMut5fn8cMhAyCSEyLJnv+/Xy1c6cc2aePCTne57t+2hKKYUQQoikZDrTBRBCCHHmSBAQQogkJkFACCGSmAQBIYRIYhIEhBAiiUkQEEKIJCZBQJxx3d3deDye2Gtd1+ns7Ozz3lAppfD7/Sd1TTAYZLgzpX0+37CuE+JsIUFAnHFPP/00+fn5BAIBAGpqasjNzeWXv/zlSX3O3/72N8aPH88LL7wwpPN9Ph+33347xcXFw7qZP/fcc9x1110nfZ0QZxMJAuKM+/CHP0wkEmHLli0A7Nq1C4BPfepTJ/U5N998M9OnTx/y+enp6fzqV7+iu7v7pL6n11tvvcU777wzrGuFOFtIEBBnhZKSEjZt2gQQaxEMh9lsPqnz7Xb7SV/Tq7CwkK1btxIMBod1vRBnA8uZLoAQALNmzeK9994DjDGB461YsYL9+/fT2dnJ9ddfz7x582LHnnnmGdavX8/48eOJRqN9ruvq6uJ3v/sdPp+PnJwcvvzlL5OSkvKBy+vz+aioqGDUqFG8//77fcoTCAT47W9/i9vtxmw2c8011zBnzpzY8aeffppt27Zhs9k477zzuPHGG9m3bx8vvvgiS5YsYfz48XR2dvLSSy8xevRo5s+fz44dO9i4cSPTpk2ju7ubJ554AoAf//jHFBcX8+abb7Jx40bMZjM2m43bb78dk8k06He+9dZbPPnkk2RkZPCDH/yAd999l+eff56SkhK++c1vfuA6EucIJcQZ1traqu699141Y8YMFQqF1M9+9jMFqIMHDyqllPra176mHn/8caWUUsFgUH36059Wr776qlJKqd/+9rfqnnvuUbquq7q6OjVq1Ci1YsUKpZRSkUhEzZ8/X61atUoppdSGDRvUxz/+8X7fb7fbldfrPakyv/baa2rfvn1q2bJl6uGHH46939XVpS688EJVU1OjlFJqx44dKi0tTfn9fqWUUp/+9KfV/fffr5RSStd1VVRUpN544w3V3t6uJkyYoN566y2llFItLS1q7ty5sZ/72WefVeXl5er2229XP/nJT9SaNWvUj3/8Y+V0OtULL7ygxowZo6LRqFJKqa985SvqD3/4Q6xMA32nUkotXbo0dkwppb7xjW+oQCBwUnUhzm3SHSTOCpMmTaKhoYHNmzczYcKE2Pv79+9n1apV3HrrrQDYbDYeeOABvvWtbwHwwAMP8M1vfhNN0xg9enSfJ+7nnnuOKVOmsGjRIgBmz55NR0cHO3fu/MDl3bt3L+PHj2fu3Lm8++67sfd/+ctfcskll3DFFVcAUFxczD333ENqaipvvvkm27dv5+677wZA0zS+9a1vMWnSJPLy8sjKyop9TmFhIePHj4+9vv7666mqqsLr9fLtb3+bBQsW8J3vfIeioiKysrJYsmRJ7Ml/0qRJbN68GWDQ7wS46aabeOWVVwDw+/2UlZVht9s/cP2Ic4d0B4mzgqZpTJ06lb/+9a989atfjb2/adMmqqqq+pxbXl5ObW0thw4dQtM0MjIy4n7mK6+8Qk9PDz//+c9j782ZM2fYA8HHOnjwID//+c9pbGzsMzi8fv16Pv/5z8de5+XlxWYQrV+/nosvvrjP5/y///f/Tup7b7jhhn7vLVy4kJKSEh544AE8Hg/bt29n1KhRQ/rOq6++mttuu422tjZWr17N4sWLT6o84twnQUCcNWbPns0zzzzDL37xi9h7Sik0Tet3rsViOWHffjAY5LrrruOTn/zkKS2nrutUVlbyhS98gWAwyKOPPkp7ezv5+flkZmYSDofjXjfYsaGKVxdPP/00v/vd7/jLX/7CqFGj+PWvf8327duH9J0pKSlcc801vPjiixw4cICPf/zjH6h84twj3UHirDF79mwKCwv7DGhOmzYtNnW0V0tLCzk5ORQVFREMBnG73XE/b9asWaxevbrPe263m6ampg9Uzu3btzNlyhTAmF1UVVUV6xKaMWNGrHulV09PDxs3bmTGjBm8+uqr/Qa+33zzTaD/DX6oi94eeughHnjggdjT/7FO9J1gtC6efvppLBZ5JkxGEgTEGReJRIhGo8yePZvzzz8/NsNH13UmT55MVVUVf/3rXwEIhUJ85zvf4Sc/+QkA3/72t/nhD3+Irus0NDSwcePGWFD43Oc+x9q1a/ntb39LQ0MDb7zxBg8++CDFxcWx725vbyccDtPa2jrk8r722mtMmzYt9rqqqiq2QO0rX/kKq1ev5ve//z1Op5O3336bu+66i8mTJzN//nymTZvGv//7v9PQ0MC2bdv4wQ9+QGZmJgBjx45l69atAPzP//wPO3fu7HPzDgQCcaej5ubmxq577733+Oc//0lrayvPPffcCb8T4JprrmHt2rVcdtllQ64DMXJoSsnOYuLMeuyxxzh06BD33nsvu3fv5uDBg7z22muUl5dz5513ous6f/7zn2lubiYcDvebcvnEE0/w/vvvU15eTnp6OocOHeITn/gEM2bMoL29nV//+tfU1tYye/ZsvvzlL2O1WgHo7OzkZz/7GX6/n9TUVG655RbOO++8Qcva1NTEQw89xMyZM7n55pvZtWsXf/zjH4lEItx2221UVVXR0dHBb37zG/bt28fEiRP5whe+QEFBAQDRaJTHHnuMt99+m7y8PD7zmc9w/vnnA3D48GEefPBBbDYbH/nIR9ixYwd1dXV885vf5IknnqC+vp6UlBQWLVrElVdeGStTfX099913H2lpaVx99dVMnTqVhx9+mO9+97sUFBQM+p29brnlFv70pz8Ne82EOHdJEBAiSUUiEf72t79RXV3N73//e374wx+e6SKJM0A6AYVIUrqu89JLL/Huu++yfPnyM10ccYZIS0AIIZKYDAwLIUQSkyAghBBJ7JwcExjuPG+Hw0FbW9spLs25R+rhKKkLg9SDYSTXQ2lpadz3pSUghBBJTIKAEEIkMQkCQgiRxM7JMYHjKaUIBALouh43wVavlpaWc34XKKUUJpOJlJSUQX9WIYQYioQHgXA4HFumP5BQKITNZhv2dwQCAaxW6wkTYFkslhGxLD4SiRAIBEhNTT3TRRFCnOMS2h20Zs0aHnzwwUHPWbFiBWvWrOHJJ58c9vfoup5UGRAtFkvcLRiFEOJkJTQIXHrppfh8vgGPe71e/H4/1dXVtLW1DTl17vGSsVskGX9mIY6llEKdpochpUdJRHIFpRSqsx3V6jz6X2c7Khzqf14kgtKjA3zS8J3Rx2eXy0Vubi5g7MDkdDqprKzsd15NTQ01NTUALF++HIfD0ed4S0vLkFsCZ2uLIRKJnFTZ7HZ7v3oYKovFMuxrRxqpC8PJ1IPu6ya4aT2azY59xjy0IWxHqcJhdJ8X5fehQkEIBVHRKKbsXMx5DrSUVPQeP9GGOiINB1DBIOaiUszFZWjpGUT27SS0awvhPdvR3e3oXg/Kb+wQp6VlYMrIRMvIxJSeiZaZhSkjC1NOHqZcB+Y8ByocIupsJOpsQkXC2GfMwTZzHqb0TJSuEz1cR2j3VnyuZqxtLvSONqKdHSifF73bC6EgmExoNjtYbZjS0tEysozvTU1Hs9nAZkezWFDhsPHzhUJgNqPZ7Gg2m3Htkf+vwmEiB/YQ3r8H5emMX2k2G5otBSJho850nezv/JSUOQuG+s86JGf0juh2u2M3PrPZTE9PT9zzqqurqa6ujr0+fjFHMBgcUl+/xWIhEol8gBKfWFNT04CLMgYSiUS49dZbYznzhyIYDA57UctIXhBzss7lulBKgd8Hnk7wdxv/hYJQUAzF5cZN50TXH9yL2raRjLJR+EpGQ8ko6H1/52ZwHobMbMjJg5RU1I73Yccm6P07sqeizZgDYydCSyOqqQFamqD3iVUpo0zBwOA/jD0VgvH//mPMFhgzHm1UJaRloKVlgAb4u9F93UZQ8HSBswl8Huj29v+MjExQEFj1TzCboWIcuJrBd+RcixWyc42fN78IrWIcWnoGpKRBNALhEIRC6D0+lN9nfEdri/F+OGTUi9UGVqvxv9HokWuCEAkfPcdkgtLRaNMvRKuoNH5+o8IgFDL+LX1H/j1tNjSLDWw2vGmZdA/z93Wg+9IZDQJmsznWt62UOiWDtvpT/4VqOBj/mKYNq0mnjRqL6abPn/hE4IUXXuCLX/ziSX2+xWI5qQAgkpdqOIj+4lPQcBA6O4ybSjyaCQqK0CZORau6ECbPQLOnoDo74FAtau921MZ10GFsphO7XaZlgNKhxw+aBo4i40bXc6RbNycf7bJr0WZdDKEAauM61Ka34J3VkJIKpRVok6uMG2Avu9343CM3U81mM46bTChPF3S5oasDMrPRSiugtMK4pq0F5XKCz4s2ehyMmXDCwNanriJh6OqEznbjpuwoRktLN7pUDuxFbX0XtW8n2oy5MGEK2vgpOKZMo729/WT/WU6K0qOgQDtLJqmc0SBQWFjIrl27APD5fOd0s7yxsZFnnnmGt99+m3HjxpGZmcnmzZu54oorePzxx5k5cyZLlizhhRdeICMjA7PZHNsYZM2aNRw4cIBbb7019trlchEOh/F6vdx+++1n8CcTQ6GUAnf70SdgMJ7u0tLRzGbjqfHAbtS+XeDtRLtwAUyahmbqOyyn9Cjs3YHauBblakYbOwltwmTIdaBe/jvqndWQmo42dRbk5hlPrJk5xtNqWobxJOtqQjXVoxrqUO+tQ6191bjppmUYN1swnoKnXID24WVoM+aSa7XQsWEd1O4CzYQ2pQrOm46WbuxApoJB6PZAbn6fMmtTLkAt+6JxLDv3pMeqBj07Jx9t/JST+rw+n22xQn6B8d+x75vMMH4y2vjJ/a85DWNtmunsuPn3SmgQiEajsa0C29raePfdd7n22mtjx8vKyujo6CAUChEMBk9JEBjsiT2R3UFlZWXccsstHDp0iMWLF9PT08P9999PUVER9957L263m3/84x94PB5uuOEGvvSlL7Fw4ULsdjsXXXQRv/vd72JBIBgMsmHDBn76059yzz33sHv37hPueCXOHLV/N/rfn4B9O+OfkJoGgYDxhG0ygc2OevNfUFiCNv8K4wbd5QZ3G2r3VvB2gT0FCkpQLz+HWnlk8NNqQ7vqY2hXf9y46Q+kojJ2c1WRMOzbidryrtG9MHoc2pjxMKoSzZ4Su8TicGCafwXMvyLuR2p2O9gL4h+zWIxgJM5JCQ0CW7Zs4corr2T//v3k5OTEAsKxli5dyurVq1m2bFkii3LapaamkpOTw5IlS7BYLBQXF3PTTTfx+uuv8/TTT9Pc3EwgEMBut/db45Cens7YsWMBY8B8sBlWYmhUJIxa9xp0tKJd+dF+N1HV2W4M2qUd9/7O99HXvGLcmH3dRrdIZs6RbotRqP17YPPbkJWD9rFbICun90oI9BjX+LuNFsGE842+c7MZ9d561OqXUf9zpBvQajP6oieej+nCBTB1NprdjgoG4MAeVHMD2gUXoeXmn9TPrVmsMLnK6KIRIo6EBoGZM2f2eb1kyZJ+5xQUFLB48eJEFuOMMZlMfW7uDz/8MLNmzWLp0qWsXbv2DJYseahIGLX+NdQ/n431f6u3X8f0mTvQJk1D73Kj/+23qNWvgMWCNvsStIVXg8WC/vc/w64tkJ0HRaVQUIKWmmZM4du5Gd5aBSmpaB++Ga36Q2gpQ1+8p827DOZdZvTRW21GkIjTFaHZU+QmLhLq7JwveY6y2+14PB7a2tro7OwkHA73OV5bW8uSJUs4fPgwjY2N7Nixg/nz5xMOh/F4PLHzIpEIoVAo9v+P/xwxMBUOG33gh/YZM1WaGoxZJ2MnYvrUv0N6JvpjD6E/9D202ZfQtuN9VMCPdtnVoOuot1ej3lplfFhGJtrSz6EtvAYtzqp35es2pgCexM3/eJp0o4gz7JzcXvL4/QT8fj9paWknvO50TBFduXIlZrOZkpISduzYQXFxMYsWLQKMcZEXX3yRqVOnkpqaSmpqKpWVlaxatQqn08mECRO48MILWbVqFa2trSxdupRnnnkGh8PB5Zdf3ud7hvozx3MuT4scjHI1o//hQThUa3TLlFaglVagTZsF58+MPWmrYAD1zB9Ra17BdsE8Ih/9FFrJKONYwI96903o8aMtuBItLf0M/kSnz0j9nThZI7keBpoiKkHgHCVBoC/93TWo//4NmMyYbv0a2gXzTniN8nZRMHbciKuL4RiJvxPDMZLr4axcJyDEUCilYMs76K88j1Z5Htp1N8ae0FVnO+qZP6E2vAnjzsP0+W+i5cefxXI8LTM7kcUW4pwgQUCc1VSrE33FH2DbRshzoPbvRr21Cu0jN0MwiHrhSYhE0JZ8Au3aG4zpikKIIZO/GHFWUT1+2LEJdWg/6lCtMffebEG74TNol/8bNNahP/UY6r8fNS6YOgvTJ25HKyw5swUX4hwlQUCcNVQkjP7z70L9ASNPTNlotEuvMhZH9c6PHz0e07d+AtvfA5MZpsyQjKpCfAASBE4zXdcxmZJjV08VDBhz831GMiwV8B9JtBU2kmLNWdhn6qV6YQXUH0C77T/QLlwQd1omHFnaP2326foxhBjRJAicRq+//jqPPvoozz777JkuSsKp+gPoD99rrLQd6Jx3VmP68nfQUtJQtTtRL/8D7eJqTPMvH/AaIcSpNeKCwGMbWzjojp+2VhtmFtGxuSl8bnbRBy0aixYt4k9/+tMH/pyznarbh/6LeyElBe2zd6BlZBnJy1LTwWak2VVbN6L++zfoP/8epi98C/1PD0OeA23p58508YVIKiMuCJwJf/vb33C5XNxxxx0899xzWK1WQqFQv2yhMPJ2BFN7tqHeXQNjJxq5cbo96L/8AaRlYPrG/WgFxXGv0y5ZjMrMQf/DT9Hv+TJEo5ju/DFa6vDWPgjRyxeK4uwO4+wO0eIN0+ILU5mbwuLx2ZiO+ftTStHsDZNmM5FtN5+2v81wVNHcHcKRZiHNeuYzio64IDDYE3uiFovNnTuXRx81Zqvk5OTQ3NyM3+/vly10pFFN9ei/ecDIkLnmFWJtrIJiTN944ITz9bWqCzHd8SP0R3+MtvBqtInnJ7zM4tRo9oZo90coyrCSl2rBbIp/Az3UGSTVYqIwI/74zgflD0fZ3uJns9PPntYeWrpDeEN9t5xMtZh4eV8na+q6+Oq8Eoozbext6+Evm1vZ1mJsaZtiMVGcYeXCMV1cWp5CRfaJ/151pahzB/EEoxRlWClIt2IZoB4AnN4Qr9R28tqBLroCRjLNTLuZ4gwrc8szqB6XQ27q6b8lj7ggcCaMHz+elpYWQqEQuq7zyU9+Mm620JFEdXvQf32/sdXevY8Y2+nt2wltLWiLrhtytktt/GRMP/9zv7z6yc7pDdHoCTGrbJCU0aeALxRlQ2M3V6RlDfmaV2s7+d2GFiK6EfYtJo2KbBuXV2azaGw2GXYzhzqD/PfmVjY0dqMBF5Skc+WEHOaUZQwYMI7lD0dxesO0dIdp7g7R0h3G2R3G1R0mEtuICtp7IugKbGaN8xypXDI6i6IMK8UZNoozrRRlWEm1mHjtQBd/fM/F11ce5LyCNDY3+8i2m7llRgFWs0ZLd5hGT4jntzp5drNiSkEq04rTaPNFaOkO0dETJS/NQvGRm/3hriBbnX66gkczI5s0KMqwcn5hGlXF6UwtSqOlO8SWZj+bnT52tfZg0uDCsgzmlmfQFTBaLHWdQf66pY0VW9uYU57JVRNyqCpO69NqSSQJAqdIdXU1L730EgUFBSM+W6iKRNB//zNwtxldOPmFALH8OyfrXA0A/7WxhV2tPXxpThET8oefRO5YulL8c4+bv2xuJRRVfG5WIUvOO/VJ5va29fBKbSdv1nkIRhX/u6eLHy4qI9M+cPdEOKr443stvLSvkxnFaXx4ch6tvgjO7hDbWvw89p6Lv2xuZZIjle0tftKsJj5Z5SCiK16t7WL5mkZyUy0sHpfN4nE5cVsH3mCUh9c3sbGpb/r0TJuJogwbY3Pt2C1Hb455qVaqitOYXJCK1Tzw71H1uByqitN59B0ne9t7+MQ0Bx+anNuvO8acls2zGw/wr9pOnt7WTl6qceMfk2unwx/hvcZu3IEouSlmLihJp6oknYJ0C64jQepQZ5C3GrzU7D86IUIDxuensGy6g+px2eSn9f+5D3uCvFrbxWsHunirwUtxhpXF43O4ojI74a0DyR10inR0dHDjjTfy0ksv8R//8R/ccccdpKSk8LWvfY0777yT+fPnE41G+chHPsL//d//feDvS3TuIBWJQHODsWVgWgbY7NDcgDpUi3r/bdi2Ee22rxsbkZzDhpsrptET4isvHoi9/tiUfG6alj/ojehEnN4Qj7zdzA5XD7NK0zFpGhsau/n6RSVcXnnqUlz8Y2c7f36/FbtZY8GYLCY5UvnDxhbG5tj54RUVpFpNKKVY3+Dl7fpuokduEU3eEAfdQT4yOY9Pzyjo90R/oCPAK7WdvN/s46JRmVx/fn4sqER1xcambv61r5P3jtzgZ5amc9X4HGYfaR3UuQP8ZE0jbf4wH52cz9g8O8UZNooyrGTYTk/fee/vg1KKiK7i/nuGojpWkzbgGEJUV+zvCLCz1U9hupVpRemDBtfjP/utei//qu1ku6sHDajMs1NVnE5VcTpTClOxDfN37IwmkAuFQthstg98Tq+zMQiAsYlOVVXVgNlC33rrLQ4ePMjYsWO56KKLPtB3JToI6P/7N9SLT8c/mJqOdtVHMV1347C+/2wy3CDwi/VNrK/38vC1Y3luRzurDnQxJsfO/dUVg/7BByI6h7tCjM9P6fO+Nxjlq/88SDCi87lZhVxemU1YV/zojcNsb/Fz14Iy5o3KHLRM7f4wBzqC5KSaKcmwkRGnHO8c9vKT1Y3Mr8jkK/OKY0/CO7s07v7nLqYWpfHRyXn8bUsbtR0BclMtpFuNm47FpPGxKXksHPvBAlKrL8y/ajup2d9FR0+E/FQLc0dlsOpAF6lWM99eUMZ5BaemZXWyzqYEcoe7gqyr97LF6WNPWw8RHb5xcSmXjhl6192xzlgQWLFiBQUFBbhcrgF3D3vssccoLy+ns7OTm2666YSfebYGgdMpkUFABQPo3/qMsU3hRYuMnbF6eqCo1Nia0FF8znbhHG84f/S9rYAPnZfHbTONrrB3D3tZvqaRS0Zn8f8ujv/HFozo/GBVAztbe/h/80v63EwfWtfEukMeHrx6DOPyjgaInrDOPa/Vc8AdZG55BjNK0plelBbrx3Z2h6ntCLCl2cdhT99N59NtJi6uyOSmaQ7y06zUuQPc9a9DjMq280B1BXbL0X9Dh8PBM+/u55dvNRuv0ywsm+7gsrHZQ+rDH46ortjQ2M2/ajvZ1ORjoiOFuxaUxe0uOV3OpiBwrJ6wzg6Xn0mO1CG3Ko53RrKIer1e/H4/1dXVPPLII3FvXPX19VgsFq6++mr+9Kc/4XK5KCwsTGSxxAmodTXg78b04WUfaKPvc9WBjgDN3SEuroj/xPXs9jYsJo2PTj7aVz+nPJOl0xw8ubWNeaMymH/cteGoYvmaRna39VCeZeNXbzspzrQxyZHKunoPa+o8fGK6o08AAEi1mrhn0SieeN/FpiYf6+q9/cpjM2ucX5jG4vHZTMpPpSsYpaU7TF1ngFUHunjjoIdrJ+ayvt5DutXMdy4t6xMAel1emY3FpOENRlk8PnvY3Q5DZTZpzBuVybxRmfjDUVIsptM2GHquSbWamJ2gSQIJDQIul4vc3FzA2CvX6XRSWVnZ55y2tjZycnIAIwrX1dX1CwI1NTXU1NQAsHz58n4b0re0tPTZxnEwQz3vbGe32/vVw0AizYdRAT/WsRMBow4GulZFo7SvehHTxPPJnbtgxK1rOFaLN4jZbO5TFy5vkB+8Xos3GGHGp4oZndv3oaXB3cPqOg83zihl/Ki+ayC+cGkem5wBfr/RxSWTyslLN7o3o7riBy/vYVOzj7uuGM+l4/L5/FOb+embTTz44fP5w8ZaJhVm8MVLJ2KJc+N1APeVFaGU4pC7h/caOtHQKMtJoTQrheIs+4BjEU1dAR57+xD/u6sVm8XEo9dPZ1JR/5tJ7+/Ex4b4OzVSDfa3MVIl9I7odrtjN12z2UxPT0+/cwoLC9m0aRMAgUAAv9/f75zq6mqqq6tjr49vroVCIZRSJ7zBj5TuoN4tJ4fSbFXBgLEYy9eN6Qe/QnMUDdrkVZvWo7c0oT76Kdrb209Zmd+q97LD5eczswrPiqe9zc0+7l3VwIemFnHrtBzMJo2orvheTT3BSBSrSeMPa2q547iunT+81YTFpHH12LS4dfjvcwr4fyvruP/lnXz6ggK2NPt5q8HLthY/t15QwPxiCxFfF99ZUMq3XjnE557ajFnT+MrlBXS6O05Y7gxgYVnv2FkUoj663L4Bz7cBX56Vz7+NyyCiKxzmAG1t/VfUn63dIKfbSK6HM9IdZDab0WNzehVmc/++rPLycsaOHcuqVavw+/3DelJPSUkhEAgQDAYHfXK12+0Eg8GT/vyziVIKk8lESkrKiU8G1MpnoaMNbDb0v/wa0x0/7Hv8wB4oKkNLN54O9X/9DziKYAg7cw1VVFf813sttPsjZKWYuXFq4p602v1h3m/2Mb0ofdAFSs/v6sBq0nhhewsdXj//cVEpT21rY2drD3fML+GgO8gLuzu4YVo+5VnGGo+tTh+vH/DwofNyB5y2V5Ft5+YqB0+838o7h7sBKEy38pmZhXz4mO6jihw7d15Syo9XH+ZTMwqoyEnsOpJEf744dyU0CBQWFrJr1y4AfD7fgM2sjIwM5s6dy1NPPTWs8QBN00hNPfFsgpEc5eNRLU2ofz2PNm8RjDsP9bffot78F3zsZpSuo/7xZ9Qrz4PNjjb/chh3HuzfjXbT7WimUzclb0NjN+3+COVZNlZsbeP8gjTOLzq5Qe36riBv13u5fFw2juMGDpVSvN/s45XaTt493I2ujJks103M4fqpDrKOG0ir7wyyudnHzVUOsjMzeHRtHS3dh6htD1A9LpvLxmYzoyTCyr1unt3Wzh0Xl+LuifDQuibKsmx8YvrgK6E/dF4eYV2RZTdTVZxOSWb8WW+zyzL46w0TzorUASJ5JTQIlJWV0dHRQSgUij2Br1y5kmuvvTZ2TjgcZv369cycOZPW1lbGjx+fyCKNWGrjWvSn/4h25UfQrvg30EzoT/0XWKxoH78FsnJQG9einv0TkXmXop74NWrDm2gLrgRdR62tgTdegrR0tItP7dz/l/a6caRZ+OmVo/nmK3X8fF0TD187huyU/r9+b9Z52NjYTWGGleIMKwp4bX8XO1uNrkR/WOfWmX0fFF7d38Vv3nGSZTfz4fPymFuewav7u/i/PW5e3d/F52cX9Zln/8LuDmxmjavH51BZXowWDvDoO04qsu3cfiTtSE6KhWsn5hqtgan5/H5jC/6wHptHPxizSRtya0cCgDjTEj5KunTpUlavXs2yZctQShGNRvsct1qtXH/99axevZqbb745aXLtn0pq1xb0P/4npKSinvkj6p3VaBdeAtvfM3bkyjG6IUy3fBX9B1+l/Y5PQSiEdv1tRtDQNNTHPo1aV4NWVIaWcurmaDd6Qmx2+rm5ykGG3cw3LynjW68c4hfrm7lnUXmf8YFwVOe/3mshENYJ64ojWQkozbRy6wUFrKv3srWl/5jRW/VeSjNtPHLdmNgA6eTCND4yOY/fb3Dyq7ebyU21cEFJOl2BCG8c9LCoMousI0HoyvE5VOam4Ei39Jk189HJeazc6+Z7rzXg7onwlbnFjJZuFTHCJDwIFBQUsHjx4tjrJUuW9Dtn1KhRjBo1vJQDyU7VH0B/9MdQWIrpW8tRO99HrfgD6rknoGSUsSXjEVpBMdrSz8Kzj8Pt38R04YKjx7Jy0K65/pSX76V9biwmuHJcDgCVeSl8dlYhv9vQwtpD3j4LX95q6KYrEOXeReVMK0qnzR+mJ6wzNteOpmkEI4qntrXRHYzGFkKFozrbXX4Wj8/pN0OmIsfO3ZeV8+1/1fPgm4387OrRrD/kJayrfqkYjl+8BZCTarQG/mdXBwvHZFE9TjamFyPPyJgvmaRUqxP9kfsgLR3T13+Alp6BduEC1JQZqH/9L9qs+f02XjddejX5H76JdndnwssXiOis2t/F/FFZ5BwzkHrVhBz+udfN09vauLgiM7YYaeVeNyWZVmaUGCkTju9Ln1acxoptsN3lj62e3d3WQyiqqCqOP8aQZjXzvYXl3PlyHQ+8cZiesM4FJelDyhIJcOPUfPJSLVw5PmdET5cVyUv6Xs5h+t9+C+GQEQDyjvZBa+mZmD76SbSKyrjXaebTE/vX1HnwhXWumZjT532TprF0qoPDnhDrjyx+OugOsKu1h2sm5A44hXRifio2s9anS2hLsx+TBtMGGWguzLDy7UvLcPnCuANRPnRe7pB/hnSbmQ9PzjvhOIAQ5yr5zT5HqYaDsON9tKs+hlZacaaL04/TG+L5ne2MzrEzOU4emPkVmYzKtvH09jZ0pXhpbyc2szZoojSrWWNKYRrbnEfnxW92+piYn3rCAdYphWl84+JSrp6QwwUl6cP/wYQYYSQInKPUv54HewrawmvOdFGI6kfTT/WmQv7aPw/SGYhy28zCuN0ovTNoGrpC1OzvYnVdFwtGZ50wL8r0ojTqu0J09kToDkbZ3xGgqmRo003nV2TxpTnF0q0jxDFkTOAcpDpajemdi66LLfIaTCiqoxRx88V8oHIoxWPvuVi5103ukbzroahiX3uAC0rS+fe5xRSkD7xg6+KKTJ7eZuN37zqJKvp1G8Uz/Ujf/9YWP1azhq5gRrE82QsxXNISOAsFIzpOb2jA46rmBVAKrfpDQ/q8X6xv5kdvHD5VxYt5cY+bF/e4mVueSVVxGkoZ2Q7/fW4x9y4qHzQAgNEaWDrNQVTBhPyUIW3MUpmbQrrVxLYWH1uafaRYTEx0nJm0w0KMBNISOAs9vsnFmkMe/vvjE/ql8VX+btSaf6HNXhDb0WswvlCUdw97T3kr4P1mH3/a5GJueQbfWlA67HxAF1dksrk5e8g50s0mjfOL0tjqNAaEpxamDrqvqxBicBIEzjIRXbG23osvpNPSHaY0q+80SbX6FQj2oF310SF93obGbiI6REJ6n/n1JysU1QlFjL5/ly/Mg282UpFt5475ww8AYNzUv3ZRyUldM60ojXeP5OW5duLQZ/oIIfqTIHCW2er04T2yefWhziAlGRY4tN9YBLZzM+zfDZOrBpz+ebz1x+Sfb+4OMcF+8l0nde4A362pxxfSY+9l283cvbD8jEydnH7MdNAqGQ8Q4gORIHAGqW4P1O5E7duF2r8LbHbeLLuaVFMeAV2jbt1bzNn8lJEFFGDUWLTqJWhXDG0soCes836zj/MLU9nh6qGlO3zSG6L3Dv6agM/OKqT3mX9WacagWToTqSLHTpbdjNmkMSp7aFuSCiHikyBwBqjODtSLT6HWvgrRKFgsMHo8YW837/SkMqd9E3uzRnPI1wXlY9E+/Em0qTPRsnJO6ns2NXUTiio+OjmfHa7DOLvDJ13Wtw93s63Fz+2zi7hu0tnR9WLSNG6a5sBsQqZ7CvEBSRA4jVSgB/XS31E1/wvRCNqCK9HmLIQx49GsNjYd7sa3+jALLjqfgEujobAY84dvGPb3rav3km03M7M0nWy7mZbugWccAexy+fGHdWYd2cYuHNV5YpOLimwbV0/IGXY5EuFsCUhCnOskCJwmyt+N/sv74MAetAsXoH3kZrTCvjv9rD3kIcNmYsbcKvZub2PDjnZCUb3PXq8r97oZn5dywmmRwYjOe03dLBxjbBRelGE9YUvgN+86aegKcXFFJl+4sIia/V04u8Pcd/mohG02LoQ4syQInAbK50X/xb1wuA7Tl76DNvOifueEojrvHO7m4tGZWM0ao3Ps6AoOd4WoPLL5uDcY5Q8bWpg3KpNvX1o26HdubvYRiCguqjASrRVn2tjT1n97z17BiE6jJ8S4PDvvHO5me4ufYFRxYVkGMyTNghAjliwWSzDl9aD//HvQWIfpy/EDAMB7TT56IjoLRhvz5Xvz1h/qPLod5tYWHwqobR/4Zt5rfYOXDJspllitOMNKqy9M5JgUD8eq7wqiK7jhfAf/ec0YHOlWdKX4zMyT3+lNCHHuOC0tgVAohM02+CyOYDCI3T6yNuxQW95FX/EH8HRi+sr30c6/YMBz1x7ykG03x27aJZk2LCatTxDY0mxkz2z1R+gMRMg5Zmeu7lCU57a30+gN0eIN0+AJctnYrNhCqqIMK7qCNl+Y4jjff9BtfM/YXDvFmTYevGo0vlA0tvGKEGJkSvhf+IoVKygoKMDlcrFs2bJ+xyORCI899hiTJ09m165d3H777ef87mKq1Wls7bh1A5SMwvSN+9HGnTfoNdtb/MwsTY/1vVuOTH+s7zomCDh95KSY6QxEqW0PMLvsaN6gN+s8PL+rg4psG8WZNqpK0rjumIVUxRlGEHZ2h5ka5/sPdARIs5pi0z7NJk0CgBBJIKF/5V6vF7/fT3V1NY888gh+v5+0tL4ZH/fs2UNOTg4LFy7k4MGDNDU1UV5enshiJZRqdaLf93VAoV1/Gy+UX8JbtX6oPQQYT+T/Mb+kzypbXyhKZyDab6OTimw7213G039Ldwhnd5hPVRXwt62t7Gvv6RMEtrb4KUiz8Mh1Y+NOmyw6cnN3DjBD6KA7yJgc+wda/SuEOPckNAi4XC5yc42n0by8PJxOJ5WVfVe6lpWV8dRTT+HxeHA6neTl5fX7nJqaGmpqagBYvnw5DsfQNvE+nsViGfa1Q9X5+MMEUeT/4i9YSsp57S/v4QtFGZuXRoc/xOo6D19dNJHCrKPbGbY6jVW955U7cDjyY+9PKQuwus6DPTOH/U5jwdjV00ex7rCPQ1499rPoSrHDVcvFY/MoKCiIW67cPIXVfABP1NKvHnSlONS1l+umFCW8fs42p+N34lwg9WBIxnpIaBBwu91YjmxvaDab6enpP6CZk5PDBRdcwN13380nPvGJfi0FgOrqaqqrq2Ov29rahlUeh8Mx7GuHQu3dgb5+FdqHltFpTUG1tuL0BLh2Yi63zSxkp8vPd16tZ8tBJ9ZjnuJ3NHQBkEGgT/kc1ggA7+9vYu0+N3mpFtKjPsZmW9nQ6KG1tRVN0zjoDtAViDAxxzzoz1eYbuVgq4dIJNLnvGZviJ6wTkmqSmj9nI0S/TtxrpB6MIzkeigtLY37fkI7381mM7pu5JtRSmE2909etnfvXqLRKD/72c949dVXcTqdiSxSwihdR3/6MchzoF1pJHfzBKOEogpHmhEIy4909xz2BPtc2+QNYdKg5Lg0DL0zhOo6g2xt8VNVnIamaUzIT8ETjOLyGfP+tzqNLqNpA+yz26s4wxp3wdgBdwCAMTn9N1sXQoxsCQ0ChYWF+P3GDcrn88VtZu3du5eKigpSU1NZuHAhW7duTWSREka9tQrq96N97Ba0I7OcWn3Gk3xvXv0su5mcFDMNXX1vxE2eEIXpVqzmvv8cjjQLaVYTbxz04A1GY8nSxucbN+vaduPmva3FR2mmDUfa4Ll8BlowdrAjiEmDihzJwyNEskloECgrK6Ojo4NQKEQwaDz9rly5ss85U6ZMYffu3Sil2LdvH5MmTUpkkU4ZpRTK04lqPoyq3Yl6/r+hchLanEtj57QeeVIvPGZzlfJsOw1dfVsCjZ4QpZn9b8CaplGRbY8t8qo6smhrTE4KFpPGvvYAUV2xvaUntuPWYIozbPhCOp5ApM/7B90BRmXZ+6xMFkIkh4TPAVy6dCmrV69m2bJlKKWIRqN9jldWVmI2m3nttdeorq5m9OjRiS7SB6bq96M//ks4XHf0TZMJ05e/22dmTqvfCAKOY4LAqCwba+o8KKXQNA2lFE3eEFMK49/ER+fY2d3WQ0W2jbxU45/LatYYm2tnX0eA2o4APRE9tr5gML0zhBq7eig4pmfuoDs4pOuFECNPwoNAQUEBixcvjr1esmRJv3NGjx59btz8IxHUymdRK5+BjCy0G26D7Dy0tAwoKkUr7Ls5issXJsWikWk7+oQ9KtuOL6zT0RMhP81KR0+EQERRlhW/K6Z3XOD4vPnj81J446CHLU4fAFOHcBMvPhIEmroCFOQZwaorEKG9J8LYvJG1UE8IMTSyGmiIVLfHSABXtw9t7kK0T9yOlp456DVtvjCONGuf1kFv/vvDnhD5aVaajuwlHK87CI72/x+7JgBgoiOVl/Z18mptJ6Nz7H1WDw+k8JggUJVnJKA7ulJYBoWFSEYSBIZA+buNBHBN9Zi+eBfarIuHdF2rL9Jvs/VRR2YINXQFqSpOp9FjBIGBWgKTHKk8uqSy3/He4ODyRVgyafBg1CvNaiY7xUyTJwAYQaCu0xhcHpsjLQEhkpGMBJ6ACvSgP/JDaDxkJIAbYgAAY2C48LggkJNiJt1m4vCRGUJNnhA2s0Z+2sDxOF6AKMu0kXJk8/gTTQ09VnGGlaauQOz1wY4g+akWSREhRJKSIDAIFQ6h//p+OLAX0+fvRJs2e8jXBiM6XcEojvS+N1dN0xiVdXSGUJPXmBl0sukazCaN8Xl2TBqcP8CgcjxFGba+QcAdZGyutAKESFby+DcI9dbrsGcb2m3/gTZr/kld2+Y/skYgztz98mwbGxq7AWj0hBkzzJvwNRNzmehIJcPWfxHeQIozrKw75OHP77twdhvZRueUZ5z4QiHEiCQtgUGoze+AowjtokUnfW28NQK9KrLtdAWiuHsitHTHXyMwFJeMzuKWC04u339lXgpRBS/sdlPnDjKzJJ2FY7OG9f1CiHOftAQGoAI9sGsL2mXXDGsz894gcHx3EBydIbSxsZuoGnhQOBEuGpXJytvnEvB2ypaRQghpCQxox/sQCaPNmDusy12+MCYN8uN1B2UZ3T/vHDa6hE5nEADITrVKABBCABIEBqQ2vw3pmTB+yrCub/OHyU21xHb2OpYj3UKKRYst9Bpud5AQQnxQEgTiUJEIautGtOmz0eJkPh2KVl8k7qAwgEnTKMuyE4oqMu1mMu3D+w4hhPigJAjEU7sT/N3D7gqC+GsEjtU7LiCtACHEmSRBIA61+R2w2uD8mcO6XleKNn847qBwr96Vw6d7PEAIIY4lQeA4SikjCEyuQrMPLZ/O7tYe7n2tHn/YyJDq7okQ0emXMuJYo47c/MukJSCEOIMkCBzvcB20u06qK+i/N7vY7PTzxkEPcHSh2GDdQePzU7CZNc4rSP1AxRVCiA9CgsAxlNeDevnvoGloVRcO6Zo9bT1sd/VgMcHKvW6UUkfXCAySDyg/zcpTN04cUgpoIYRIlNOyWCwUCmGznb3dHqrVifrX86j1r0EohHbZtWhZuUO69u872sm0mbhpuoP/2uhih6sntvfvYN1BgMzVF0KccQkPAitWrKCgoACXy8WyZcv6Hd+xYwdPPvkkmZmZRKNRJk2axPXXX5/oYsWoaBT9p3eBz4s2bxHa4g+jlVYM6dqGriDvHO5m6bR8Fo/LYcXWNlbudRuZQq0m0k8ip48QQpwJCQ0CXq8Xv99PdXU1jzzyCH6/n7S0vt0f0WiU73//+6SkpLB+/XqmTp2ayCL1d6gWutxon78T0zH7Aw/F8zs7sJk1/m1iLnaLiSsqs3lxj5vKvJQ+W0oKIcTZKqFBwOVykZtrdKvk5eXhdDqprKzsc8706dMB0HUdj8dDVlb/ZGY1NTXU1NQAsHz5chwOx7DKY7FY+l3b/fqL+ADHxYswZQ+tCwigxRtkdd0ePjq9mMryYgCWzU3nf3e/x772ABePzR12ORMtXj0kK6kLg9SDIRnrIaFBwO12Y7EYX2E2m+np6Rnw3E2bNjFu3Li4x6qrq6muro69bmtrG1Z5HA5Hv2uj770Fo8bSEY7CSXzuXza50JXiytFpsc9MAS4oSef9Zh9ZFjXsciZavHpIVlIXBqkHw0iuh9LS0rjvJ3R2kNlsRtd1wJh/bx4kBcOWLVtO+2bzKhiE/bvQJlfFPd7kCfHdVw/RHYz2O7bD5WdqYVps395e10zMAU48KCyEEGeDIQWB2traYX14YWEhfr8fAJ/PN2gzq6Wl5fTPIKrdCZHIgEFgs9PHDlcPe9r6tmCUUjR5QpRn9y/v7NIMbq5ycOkYydEvhDj7DSkIbN++nRdeeIGtW7cSjfZ/Kh5IWVkZHR0dhEIhgkFjO8WVK1fGPbf3+Omkdm0BswUmnB/3eLPX2Af48JHN4Ht1BaP4wnrcvD9mk8aNUx3SEhBCnBOGNCYwc+ZMKioqaGtrY82aNQSDQXJycqiqqiI1dfAVr0uXLmX16tUsW7YMpdSAQeTGG288+dJ/QGrXFhg3acD0EM1eY75/43FBoOnIa8n7I4Q41w0pCPTe6AOBAG63m/fff5+0NGNAVNd1lixZMuDuWwUFBSxevDj2esmSJXHPO//8+E/jiaK6PdBwAG3JJwY852hLoG8rpVGCgBBihBhSEFi7di2vv/46JSUlXHTRRdx1111kZBibk//jH/9g9+7dTJ48OaEFPeX2bAOlBhwPiOoKZ7fREji+O6jJG8Ji0nAMsF+AEEKcK4YUBEpKSvjxj38cu/Efq7KykjFjxpzqciWc2rkF7KkwZkLc4x09ESK6ojTTRpM3hDcYjW3+0ugJUZIpWzQKIc59QxoYnjdvHi6Xi0jEyI7pdrs5dOgQADNmzDjhuMDZSO3eApOmolnix8GmI11BF5alA33HBZq8IdkMRggxIgwpCGzYsIHHH3+clpYWAHJzczl48CD19fUJLVyiqHYXuJrRJk8f8Jze8YDZZUbrp/HIuEBUVzR7wzIeIIQYEYYUBNxuNz/60Y8oKyuLvTd9+nTeeeedhBUsoeoPAKCNG3gco9kbxmrSmFKYhsWkxcYFWn1hIrqSICCEGBGGFAQ0TaO9vb3Pe01NTaSkDG3nrbONam02/k9h/GXUYLQEijOtWEwaJZnWWHdQbzeRdAcJIUaCIQ0ML1iwgIceeohZs2ZRWFhIfX0969at4/vf/36iy5cYrmZIz0RL7z/Q3cvpDcdu9OVZNuq7jJt/bzAolZaAEGIEGFJLICUlhTvvvBOTycTOnTtJS0vjvvvui5vx81ygXM1QWDLgcV0pmrtDlBwJAmVZdpzeEBFd0egJkW41kW2XvQKEEOe+IWcRtdvtXHnllbHXO3bswOFwUFRUlJCCJZSrGW3ceQMedvdECEUVxUeSw5Vn2YgqcHpDxsygLNuAi+OEEOJcMqQg0NnZyW9+85s+KVYjkQhLly4954KAioShow0uGrgl0Jsuorcl0Jso7rAnRJMnxPmFsi+wEGJkGFIQ2LhxI1/96lfx+/00NzdzwQUX8O677zJlypREl+/Ua3OB0qFgsCBg9PuXZBotgd6ZQPs7ArT6IzIeIIQYMYY0JmCxWMjKyqKwsJCGhgYALrzwQt5+++2EFi4hjswM0gqLBzyl2RvCYiKWFiLNaiYv1cLGxm5AZgYJIUaOIQWBsrIyvve977Fz5046OzvZsGED69atw+fzJbp8p5xy9U4PHaQl0B2mKMPWJy1EeZaNA25jwZisERBCjBRDCgITJkzg5ptvpqKiguuvv549e/awb9++PtlBzxmtTiNnUGbOgKc0e0OUHLdj2LE3/hJpCQghRoghjQls27YNq9UamxL6yU9+MqGFSiRjemjxgLN7lFI0e0NMPW7wtzcI5KdaSLUmdFdOIYQ4bYZ0N9u8eTPhcHjYXxIKhU7JOaeEq3nQQeHOQJRARPV72i/PtgOySEwIMbIMKQhMmzYt7vaPTU1NJ7x2xYoVrFmzhieffHLQc9avX8/f//73oRRn2FQ0Cm0taIONBxw3M6hX+ZGbvwwKCyFGkiEFgfz8fN58802eeeYZ1q9fz/r161m7di1btmwZ9Dqv14vf76e6upq2trbYpvPH6uzspKuri8suu4z29vaT2sP4ZOntLohGBh8UjgWBvjf7/DQLc8szmDdq4FQTQghxrhnSmIDb7SYQCKBpGo2NjQBEo9G4m8wcy+VykZubC0BeXh5Op5PKyso+5xw+fJicnBycTie33norZnP/dAw1NTXU1NQAsHz5chwOx1CK3U9k+yYAciach22Az+ja68Ns0pg8ugTLcZvG/OfHC4b1vWcbi8Uy7DocaaQuDFIPhmSshyEFgcrKSm677TaKi/vOrT9w4MCg17ndbixHNm0xm8309PT0O6d3AVpHRwd/+ctf+NKXvkRmZmafc6qrq6muro69Pnbl8slIO2xshNNlS0Ub4DP2ON0UpVvp7GiPe3wkcDgcw67DkUbqwiD1YBjJ9VBaGj9r8pC6g8xmMzabjY6Ojj7/dXV1nfA6XdcBY9ZNvKd8k8nEmDFjmDJlChMmTDhhF9MHEXUeBosVcvIHPGdvW4AJ+edmimwhhDhZQ2oJbNmyheeee46cnByUUiilcDqdLF26dNDrCgsL2bVrFwA+ny9uMysrKwuv1wsYQcMywHaPp0LU2QgFxWim+LGv3R+moyciQUAIkTSGdMedMWMGU6dO7TMGsGvXLqxW6yBXGSuNOzo6CIVCsdlFK1eu5Nprr42dU1lZyYoVKwiHw+zdu5fLLrtsGD/G0ESbDw86KLy3LQDARMe5t2eyEEIMx5D3Ezh+EHjy5Mls3779hNcuXbqU1atXs2zZMjRN6zf7x2Kx8OUvf5nXX3+d66+/PmF7FChdJ+JsRBtkjcDe9h4sJqjMtSekDEIIcbYZUktg06ZNrF+/PvZaKUVHRwfXXHPNCa8tKCjok15iyZIlcc85dq+ChOhyQyg4eEugPcDY3BSsZlkRLIRIDkMKAllZWVx88cVkZ2fH3svOziY/f+AB1rNOLHto/CAQ1RW17QGuqDw3d0sTQojhGNIj7/jx48nOzqaiooLKykpyc3Pp7u5OdNlOqRNlD23oChKI6DIeIIRIKkMKAhs2bOCJJ56gpaUFgNzcXA4ePEh9fX1CC3dKuZrBbIa8+Au+9rUfGRTOlyAghEgeQ14x/MMf/rDPe9OnT+e1116joqIiIQU71bQJU0jLyiIQZ60CGIPCGTZTv5xBQggxkg2pJaBpGu3tfVfQNjU1kZJy7syn16bNJuOmzw143FgkliobyAshksqQWgILFizgoYceYtasWRQWFlJfX8+6dev4/ve/n+jynRaBiE59V5C5khxOCJFkhrxO4M4778RkMrFz507S0tK47777Ejan/3Tb3x5AVzIeIIRIPkPO0dDY2Mjll1+OxWLB7XbT2trK6NGjE1m202ZPu5HYTtJFCCGSzZBnBz3++OPn9uygQextC1CcYSU7JXF5i4QQ4mw0pCDgdrv50Y9+RFlZWey96dOn88477ySsYKdTbXuPtAKEEEkpaWYHDURXivaeSL+dxIQQIhkk/ewgX0hHV5Blj79+QAghRrKTnh20a9cu0tLSuOuuu9i9e3eiy5dwnqCR1TRTgoAQIgkNOV1mV1cXGRkZRCIR3nzzTe6++26am5sTWbbTwhOMANISEEIkpwG7g5xOJ+vXr2ffvn3U19eTn59PdnY2U6dO5brrrsPhcFBbW3s6y5oQ0hIQQiSzAYOA3W7HYrEwevRoFixYQFlZGT6fj5ycnNg2kePHjx/Sl4RCIWy2s3Pg1XskCEhLQAiRjAYMArm5uXzoQx+KvW5ubqa+vp62tjbq6uqwWq0EAgEWLFgw6BesWLGCgoICXC4Xy5Yt63e8o6ODX/ziF6Snp5OamsrXv/71D/DjnDxPLAjIGgEhRPIZ8p2vpKSEkpKjufg7Oztjm8gPxOv14vf7qa6u5pFHHsHv95OWltbnnEgkwmc+8xnGjh17kkU/NbzBKFaTRopFEscJIZLPsB9/c3JyuOiiiwY9x+VykZubC0BeXh5Op5PKyso+50SjUXp6eli7di3jxo3rE2h61dTUUFNTA8Dy5ctj3VEny2Kx9Ls2hJucNCsFBfH3GRiJ4tVDspK6MEg9GJKxHhLaB+J2u7FYjK8wm8309PTEPe/QoUMsWrSIX//613zuc58jJyenz/Hq6mqqq6tjr9va2oZVHofD0e9al8dHhlUb9meei+LVQ7KSujBIPRhGcj2UlpbGfT+hO6qbzWZ0XQeMzenNcTZ0KSkp4ZprriElJYUpU6awbdu2RBapH08gKjODhBBJK6FBoLCwEL/fD4DP54vbzHI6nWzZsgWAQCBAaurpTefsCUZlZpAQImklNAiUlZXR0dFBKBQiGAwCsHLlyj7nuN1u2tvbCYVC7N27l6lTpyaySP14gxEJAkKIpJXweZFLly5l9erVLFu2DKUU0Wi0z/HJkycTDodZs2YNn/3sZ09rUrqorugO6RIEhBBJK+FBoKCggMWLF8deL1mypN8506dPT3Qx4uoORVHIGgEhRPJKaHfQ2U5SRgghkp0EASRlhBAieSV1EJC8QUKIZJfUQUC6g4QQyU6CANISEEIkr6QOAt5gFLtZw25J6moQQiSxpL77eWShmBAiySV3EAhEyUqRICCESF7JHQSCUTJloZgQIoklfRCQ7iAhRDJL6iDglSAghEhySRsEIrrCF5bkcUKI5Ja0QUBWCwshhAQBCQJCiKSWtEFAUkYIIcRpCgKhUOiUnncqeIIRQFoCQojklvAgsGLFCtasWcOTTz456Hkul4s//vGPiS5OjLQEhBAiwUHA6/Xi9/uprq6mra0ttul8PCtXriQcDieyOH1I8jghhEjw9pIul4vc3FwA8vLycDqdVFZW9juvrq6O4uJiPB5P3M+pqamhpqYGgOXLl+NwOIZVHovFErs2rHlIs5kpKSoc1medy46th2QndWGQejAkYz0kNAi43W4sFuMrzGYzPT09cc/bvHkz8+bNY+/evXGPV1dXU11dHXvd1tY2rPI4HI7Yta7ObjJtpmF/1rns2HpIdlIXBqkHw0iuh9LS0rjvJ7Q7yGw2o+s6AEopzOb+XS87duxg6tSpiSxGXJIyQgghEhwECgsLY+MAPp8vbjPL5/PR0dHB1q1b6ejo4NChQ4ksUowEASGESHAQKCsro6Ojg1AoRDAYBIwB4GPNmTOHOXPmMHXqVHJzcxk9enQiixRjZBCVICCESG4JnyK6dOlSVq9ezbJly9A0jWg0Gve8uro6qqqqaGxsTHSRAGkJCCEEJHhgGKCgoIDFixfHXi9ZsiTuefPnz090UWLCUZ1ARJLHCSFEUqaNOLpGQDaUEUIkt6QMApI8TgghDEkZBLokZYQQQgDJGgQCRhDIlk3mhRBJLkmDgJFBNDtFxgSEEMktSYNAFJMGGbak/PGFECImKe+CXcEI2XYzJk0700URQogzKjmDQCBKlnQFCSFE8gYBGRQWQohkDQLBCDmyUEwIIZI0CEhLQAghgCQMAuGojj+skyVBQAghki8I9K4WzpGBYSGESMIg0LtaWFJGCCFEMgYBY7WwdAcJIcRpCgKhUOiE54TD4dNQEugMSHeQEEL0SvidcMWKFRQUFOByuVi2bFm/45FIhFWrVmG329m2bRtf/OIXsVgSVyxPsDdvkLQEhBAioS0Br9eL3++nurqatra22Kbzxzp8+DCdnZ0sXLiQrKws6urqElkkugJRrCaNVEvS9YQJIUQ/CW0JuFwucnNzAcjLy8PpdFJZWdnnnDFjxpCVlQVAZ2cnBQUF/T6npqaGmpoaAJYvX47D4RhWeSwWCwFlITfNGvd7koXFYhl2HY40UhcGqQdDMtZDQoOA2+2Ode2YzWZ6enrinpeZmcmzzz5Lbm4u2dnZ/Y5XV1dTXV0de93W1jas8jgcDlq6fGTatGF/xkjgcDiS+uc/ltSFQerBMJLrobS0NO77Ce0TMZvN6LoOgFIKszl+P7zVauWGG27AbrezZcuWRBYJTzBKtqSMEEIIIMFBoLCwMDYO4PP54jazNm7cyPPPPw9Afn4+Xq83kUWiKxCRQWEhhDgioUGgrKyMjo4OQqEQwWAQgJUrV/Y5p7CwkPz8fHRdZ8+ePZx33nkJK49Sis5AVHYUE0KIIxJ+N1y6dCmrV69m2bJlKKWIRqN9jldUVADwxhtv8JGPfCShgzI9YZ1QVMlqYSGEOCLhQaCgoIDFixfHXi9ZsqTfORUVFbFgkEidPcaCNOkOEkIIQ1JNlnfHgoB0BwkhBCRbEPAb6SukJSCEEIYkCwJHWgIyRVQIIYAkCwIyJiCEEH0lVRBw94RJsWjYJW+QEEIAyRYE/GEZFBZCiGMkVxDoCcsaASGEOEZSBYHOHmkJCCHEsZIqCBjdQdISEEKIXkkTBJRS0h0khBDHSZog4AvpRHUl3UFCCHGMpAkCXUEjcZ10BwkhxFHJEwQCvRvMS0tACCF6JVEQONISkDEBIYSISZog0BlrCUgQEEKIXqclCIRCoROeE4lEEloGz5ExgSxJHieEEDEJvyOuWLGCgoICXC4Xy5Yt63c8EAiwdu1a7HY7u3bt4pZbbsFut5/ycnQFo2TazVjN2in/bCGEOFcltCXg9Xrx+/1UV1fT1tYW23T+WJs3b6aiooIFCxZQXFzMpk2bElKWz80q5LnbLkzIZwshxLkqoUHA5XKRm5sLQF5eHk6ns985Y8aMoaGhAYADBw5QVFSUkLKYNI0M6QoSQog+EnpXdLvdWCzGV5jNZnp6evqdU1xcTHFxMbW1tWRlZVFZWdnvnJqaGmpqagBYvnz5sDejt1gsCd3I/lwh9XCU1IVB6sGQjPWQ0CBgNpvRdR0w0jaYzfFn5ni9XtavX8+tt94a93h1dTXV1dWx121tbcMqj8PhGPa1I4nUw1FSFwapB8NIrofS0tK47ye0O6iwsDA2DuDz+QaMsK+99ho33XQTJpOJ1tbWRBZJCCHEMRIaBMrKyujo6CAUChEMBgFYuXJln3OcTicej4fNmzdTU1NDY2NjIoskhBDiGAlfJ7B06VJWr17NsmXL0DSNaDTa57imaZSVleH1etE0Le6YgBBCiMRI+HSZgoICFi9eHHu9ZMmSPseLiooSNiNICCHE4JImbYQQQoj+NKWUOtOFEEIIcWYkVUvg29/+9pkuwllB6uEoqQuD1IMhGeshqYKAEEKIviQICCFEEkuqIHDsquNkJvVwlNSFQerBkIz1IAPDQgiRxJKqJSCEEKKvpAoCQ9nhbCQ7fve2ZK6PY3/2ZK2H43/uZK2H3pQ2vZKtHpImwf6JdjgbyeLt3vaPf/wjaevD5XLx97//nS996UtJ+3uxYsUKSkpKaG9v5+Mf/3hS1kMkEuGxxx5j8uTJ7Nq1i9tvv52nn3466eohKVoCQ9nhbCQ7fve29957L6nrY+XKlYTD4aT9vejs7KSrq4vLLruM9vZ2Ojs7k7Ie9uzZQ05ODgsXLiQlJYW9e/cmZT0kRRAYyg5nI9nxu7cVFhYmbX3U1dVRXFwMJO/vxeHDh8nJycHpdHLrrbfS3t6elPVQVlbGjh078Hg8OJ1OdF1PynpIiiAwlB3ORrLi4mKuuOKK2O5tnZ2dSVsfmzdvZsaMGUDy/l74/X6am5vp6Ojg4YcfpqGhISnrIScnhwsuuIC7776bSy+9FL/fn5T1kBRBYKg7nI1kx+7elqz1sWPHDqZOnRp7naz1YDKZGDNmDFOmTGHChAlYLJakrIe9e/cSjUb52c9+xquvvkpbW1tS1kNSBIGh7nA2kh27e5vdbk/K+vD5fHR0dLB161Y6OjrIy8tLynrIysrC6/UCRiB0uVxJWQ979+6loqKC1NRUFi5ciMlkSsp6SIogcPwOZ8nyj9vr+N3bQqFQUtbHnDlzmDNnDlOnTiU3N5fRo0cnZT1UVlZy8OBBwuEwe/fupbq6OinrYcqUKezevRulFPv27WPSpElJWQ9Js2K4tbWVzZs3M2vWLPLy8s50cU6rlpYWtm/fHnt94YUXEgwGk7Y+1q9fTygUYsKECdhstqSsh9bWVt5//30mTpzImDFjkvbv49ChQ+zbt49x48YxduzYpKyHpAkCQggh+kuK7iAhhBDxSRAQQogkJkFACCGSWNLkDhJiMNu3b6elpQVN0+gdJps7dy4ZGRkf+LPr6+sJBAJMnDjxA3+WEKeatASEACZNmsQTTzzBvHnzqKqqYv369TQ2Np6Sz967dy9vvPHGKfksIU41CQJCAFarFbPZTFpaGg6Hg89+9rOnLG1AeXn5KfkcIRJBuoOEOE5vfiGTycSaNWsoLy9n69atTJkyJdal43K52LhxIyaTidmzZ8cWFvX09PDmm2+ilCI3N5c5c+bEPnf79u3U1tYybtw4pk2bBkBzczNbt24lPT2dSCTCZZdddtp/XpHcpCUgxBFKKdatW8frr78OGInWHn/8cfx+P0uWLOHll1+mrq4Ol8vFX//6V6688kqqq6t57rnnaGtrIxAI8NBDDzFz5kyuuuoq/u///o/9+/cDsH//frKzs/nQhz7EU089hdfrRdd1fvWrX7Fo0SIuvvhiuru72b1795msApGEpCUgxBGapjFv3jxaWloAI71CdnZ2LOlcdXU1q1atwmw2c+WVV8YyTl566aW8/PLLFBYWMmvWrFir4Atf+AJFRUXs37+fcePGMWrUKACys7PxeDykp6fjdrtZv3498+fP59/+7d/weDxn4CcXyUxaAkIcw2w2M3369LjHcnNzaW9vp7W1tU9Kgd7c/C6Xi8LCwtj75eXlWK3WAb/LZDJx33330dDQwF133cUTTzyB3W4/dT+MEEMgQUCI44wfPx6lFC+//HKf9z0eD7m5ueTn59PR0RF7v7Ozk4KCAgoKCqivr+9zzbHnHa+2thabzcanPvUpHnroIUKhkMwiEqedBAEhMPabDYfDBAIBwuEwK1aswGazEQgE2LdvH7quU1NTw6JFi1i8eDEvvfQSkUiESCRCTU0NV111FQsWLGDt2rVs3bqV9vZ2Xn/9dTweD9FoNJanHoi9Liws5D//8z9pa2vDZDJhtVopKCg4g7UgkpEkkBMCeO+992hoaMBmsxGJRNB1nUsuuYT777+fW2+9lbq6uj6zg5qamti8eTNms5kZM2ZQVFQEQFdXF6tXryYQCDB37lxGjx7NG2+8QVdXFwsWLKCnp4cNGzZQWlrKnDlz2LhxI263G6/Xy+jRo5k1a9aZrAaRhCQICDGA+vp67rnnHr773e/Kal8xYkkQEGIAzc3NeL1eUlJSqKioONPFESIhJAgIIUQSk4FhIYRIYhIEhBAiiUkQEEKIJCZBQAghkpgEASGESGL/H7wwAsHModEYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred = model.predict(x_test)\n",
    "flower_class = np.argmax(pred, axis=1)\n",
    "\n",
    "# 轉為DataFrame並儲存\n",
    "df_pred = pd.DataFrame(flower_class)\n",
    "df_pred.columns = ['flower_class']\n",
    "df_pred['id'] = test_id\n",
    "df_pred = df_pred[['id', 'flower_class']]\n",
    "df_pred.to_csv('Submission_datagen_10_0.2_inceptionv3_val_acc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
